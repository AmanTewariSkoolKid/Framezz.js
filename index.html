<!-- 
  HTML DOCUMENT DECLARATION AND SETUP
  
  Think of this HTML file like a blueprint for a house. Just like a blueprint tells builders
  what rooms go where and how they connect, this HTML tells the web browser what content
  to display and how to arrange it on the page.
  
  This is a video annotation tool - imagine having a video and being able to draw boxes
  around objects (like people, cars, etc.) and have the computer remember where those
  boxes are in each frame. That's what this tool does!
-->

<!doctype html> <!-- This line tells the browser "Hey, this is modern HTML!" -->

<html lang="en"> <!-- This starts our HTML document and says it's written in English -->
  <head>
    <!-- 
      The HEAD section is like the "behind the scenes" information about our webpage.
      Users don't see this content directly, but it tells the browser important setup info.
      Think of it like the ingredients list on a recipe - you need to know what's required
      before you start cooking!
    -->
    
    <!-- This tells the browser what kind of text encoding to use (UTF-8 handles most languages) -->
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    
    <!-- This is what appears in the browser tab at the top of the window -->
    <title>framez.js  A pure Javascript video annotation tool</title>
    
    <!-- This connects our HTML to a CSS file that makes everything look pretty -->
    <!-- Think of CSS like interior decorating - it makes the basic structure look nice -->
    <link rel="stylesheet" type="text/css" href="dist/style.css" />
  </head>
  <body>
    <!-- 
      THE BODY SECTION - This is where all the visible content lives!
      Everything between <body> and </body> is what users actually see on the webpage.
      Think of this like the main floor plan of a house - this is where people actually live and interact.
    -->
    
    <!-- The main heading - like putting a big sign on your store that says what it does -->
    <h1>framez.js  A pure Javascript video annotation tool</h1>

    <!-- 
      ORDERED LIST - THE STEP-BY-STEP WORKFLOW
      
      An <ol> (ordered list) is like a recipe or instruction manual. Each <li> (list item) 
      is a step that users need to follow in order. The browser automatically numbers them 1, 2, 3, etc.
      
      This particular list guides users through the entire process of annotating a video,
      from start to finish. It's designed to be foolproof - just follow the steps!
    -->
    <ol>
      <li>
        <!-- 
          STEP 1: INTRODUCTION TO THE TOOL
          This first step is like the "welcome mat" of the application. It explains what
          the tool does and sets expectations for the user. Think of it like reading
          the back of a box before opening a new game - you want to know what you're getting into!
        -->
        <p>framez.js is a pure Javascript video annotation tool, which allows you to annotate videos in your browser.</p>
        <p>This tool can be used to easily annotate a video, without having to install anything.</p>
        <p>Optical flow is used to track your annotations, so that have to do as little work as possible ;-)</p>
        <p>This tool works best in Chrome, and has also been successfully tested in Firefox.</p>
      </li>
      <li>
        <!-- 
          STEP 2: FILE INPUT SECTION
          This is where users choose their files. Think of it like choosing ingredients for cooking:
          - You can either start fresh with a new video (like buying fresh ingredients)
          - Or you can continue with work you already started (like using leftovers from yesterday)
          
          The "input type='file'" creates those "Choose File" buttons you see on websites.
          The "accept" attribute tells the browser what types of files are allowed - it's like
          having a bouncer at a club who only lets in certain types of people!
        -->
        <p>To start a new video annotation, select a video file: <input type="file" id="videoFile" accept="video/*" /></p> 
        <!-- The "accept='video/*'" means "accept any type of video file" (MP4, AVI, etc.) -->
        
        <p>To resume a previous annotation, select a frames zip archive: <input type="file" id="zipFile" accept=".zip" /></p>
        <!-- The "accept='.zip'" means only ZIP files are allowed here -->
        
        <p>Note: Keep the focus on the browser during the entire extraction process, or frames might be skipped.</p>
        <!-- This is like saying "don't walk away from the stove while cooking" - stay focused! -->
        
        <!-- 
          These next two paragraphs are "output areas" - they start empty but will be filled
          with information by JavaScript code later. Think of them like empty picture frames
          that will have photos put in them later.
        -->
        <p class="output" id="videoDimensions"></p> <!-- Will show video size like "1920x1080" -->
        <p class="output" id="extractionProgress"></p> <!-- Will show progress like "50% complete" -->
      </li>
      <li>
        <!-- 
          STEP 3: DOWNLOAD EXTRACTED FRAMES
          After the tool breaks down the video into individual frames (like taking apart
          a flip-book into separate pages), this button lets you download all those frames
          as a ZIP file. Think of it like getting a folder full of photos from your video.
          
          The "disabled='disabled'" means this button starts "grayed out" and unusable - 
          it only becomes clickable after the previous steps are completed.
        -->
        <p>Download the extracted frames zip archive: <input type="button" id="downloadFrames" value="Get frames zip archive" disabled="disabled" /></p>
        <!-- This button will become enabled by JavaScript once frame extraction is complete -->
      </li>
      <li>
        <!-- 
          STEP 4: OPTIONAL ANNOTATION FILE LOADING
          This is like importing a rough draft of your homework that you want to finish.
          Sometimes you might already have some automatic annotations (maybe from AI software)
          or previous work that you want to continue improving.
          
          XML is a file format (like .txt or .doc) that stores structured data.
          Think of it like a very organized filing cabinet where information is stored
          in a specific, predictable way.
        -->
        <p>Optional: Load an existing -compatible XML annotation file: <input type="file" id="xmlFile" accept=".xml" disabled="true" /></p>
        <!-- This input is also disabled initially and will be enabled by JavaScript later -->
        
        <p>This is useful for example if:</p>
        <ul>
          <!-- 
            UNORDERED LIST - This creates bullet points (unlike the numbered list above)
            Think of this like a shopping list where order doesn't matter
          -->
          <li>You are resuming a previous annotation.</li> <!-- Continuing work you started before -->
          <li>You already have a first version of your automatic object detector, which you want to improve by manually correcting its errors.</li>
          <!-- Like having a robot assistant that did 80% of the work, but you need to fix its mistakes -->
        </ul>
        <p>Note: Launch your object detector on the extracted frames rather than on the original video to avoid frame/annotation mismatches!</p>
        <!-- This is important technical advice - like making sure you're working with the same ingredients your recipe calls for -->
      </li>
      <li>
        <!-- 
          STEP 5: THE MAIN ANNOTATION INTERFACE
          This is the heart of the application - where the actual work happens!
          Think of this like the main workspace where you'll spend most of your time,
          similar to how a photo editing program has a main canvas where you do your work.
        -->
        <p>Manually annotate the frame sequence:</p>
        
        <!-- 
          INSTRUCTIONS FOR CREATING BOUNDING BOXES
          A "bounding box" is like drawing a rectangle around an object in the video.
          Imagine outlining a person or car with a highlighter - that's what this does digitally.
        -->
        <p>To create a new bounding box, first click 'n' (for new), and then left click on two locations in the video corresponding to the corners of the box.</p>
        
        <!-- 
          KEYBOARD SHORTCUTS AND TIPS
          These are like hotkeys in video games - shortcuts that make you work faster.
          Professional video editors use these kinds of shortcuts all the time.
        -->
        <p>Tip: Use the spacebar to play/pause the video, and the left and right arrows to navigate frame by frame.</p>
        <p>Tip: The visibility of each object can be toggled with its visibility checkbox under the video.</p>
        <p>Tip: Zoom in with your browser to place the bounding boxes more accurately.</p>
        
        <!-- 
          THE VIDEO CANVAS CONTAINER
          This div (division/container) will hold the actual video and drawing area.
          Think of it like a picture frame - it defines the space where the video will appear.
          The id="doodle" gives it a unique name so JavaScript can find and control it.
        -->
        <div id="doodle">
          <!-- 
            THE DRAWING CANVAS
            This is where the magic happens! A canvas is like a digital whiteboard where
            you can draw, but it's overlaid on top of the video. It's like having
            transparent paper over a photo that you can draw on.
          -->
          <canvas id="canvas"></canvas>
        </div>
        
        <!-- 
          VIDEO CONTROL BUTTONS
          These work just like the play/pause buttons on YouTube or Netflix.
          Notice how they start disabled (grayed out) until a video is loaded.
        -->
        <p><input type="button" id="play" value="Play" disabled="true" /><input type="button" id="pause" value="Pause" disabled="true" style="display: none;" /></p>
        <!-- The pause button is hidden initially (display: none) and will be shown when video plays -->
        
        <!-- 
          FULL-FLEDGED PLAYBACK CONTROLS
          Advanced video playback controls with frame-by-frame navigation
        -->
        <div id="playback-controls" style="text-align: center; margin: 10px 0; padding: 10px; border: 1px solid #ccc; background-color: #f9f9f9;">
          <button id="skipToStart" disabled="true" title="Skip to Start">⏮</button>
          <button id="skip10FramesBack" disabled="true" title="Skip 10 Frames Back">⏪</button>
          <button id="skip1FrameBack" disabled="true" title="Skip 1 Frame Back">⏴</button>
          <button id="playPauseToggle" disabled="true" title="Play/Pause">⏯</button>
          <button id="skip1FrameAhead" disabled="true" title="Skip 1 Frame Ahead">⏵</button>
          <button id="skip10FramesAhead" disabled="true" title="Skip 10 Frames Ahead">⏩</button>
          <button id="skipToEnd" disabled="true" title="Skip to End">⏭</button>
        </div>
        
        <!-- 
          VIDEO TIMELINE SLIDER
          This will become a slider (like a volume control) that lets you scrub through
          the video timeline. Think of it like the progress bar on YouTube that you can
          click and drag to jump to different parts of the video.
        -->
        <div id="slider"></div>
        
        <!-- 
          PLAYBACK SPEED CONTROL
          This lets you speed up or slow down the video playback.
          "1.00" means normal speed, "2.00" would be double speed, "0.50" would be half speed.
          The "size='4'" means the input box will be 4 characters wide.
        -->
        <p><label for="speed">Speed multiplier: </label><input type="text" id="speed" value="1.00" size="4" /></p>
        
        <!-- 
          OBJECTS PANEL
          This empty div will be populated by JavaScript to show a list of all the objects
          you've annotated. Think of it like a layers panel in Photoshop - it shows all
          the different things you're tracking in your video.
        -->
        <div id="objects"></div>
        
        <!-- 
          ANNOTATION CLASS MANAGEMENT SECTION
          This section allows users to create custom annotation classes with unique colors
          during runtime. Think of it like creating custom labels with different colored
          highlighters for different types of defects or objects.
        -->
        <div id="classManagement" style="margin-top: 20px; padding: 15px; border: 2px solid #ccc; border-radius: 5px; background-color: #f9f9f9;">
          <h3>Annotation Class Management</h3>
          
          <!-- Create New Class Section -->
          <div id="classCreation" style="margin-bottom: 15px;">
            <h4>Create New Class:</h4>
            <p>
              <label for="newClassName">Class Name: </label>
              <input type="text" id="newClassName" placeholder="Enter class name (e.g., cracks, spalling)" style="margin-right: 10px;" />
              <label for="newClassColor">Color: </label>
              <input type="color" id="newClassColor" value="#FF0000" style="margin-right: 10px;" />
              <input type="button" id="addClassButton" value="Add Class" />
            </p>
          </div>
          
          <!-- Available Classes Display -->
          <div id="classDisplay">
            <h4>Available Classes:</h4>
            <ul id="classList" style="list-style-type: none; padding: 0;"></ul>
            <p style="margin-top: 10px;">
              <input type="button" id="resetClassesButton" value="Reset to Defaults" onclick="resetToDefaultClasses()" style="background: #ff6666; color: white; border: none; padding: 5px 10px; border-radius: 3px; cursor: pointer;" />
            </p>
          </div>
          
          <!-- Class Selection for Annotations -->
          <div id="classSelection" style="margin-top: 15px;">
            <h4>Select Class for New Annotations:</h4>
            <p>
              <label for="annotationClass">Current Class: </label>
              <select id="annotationClass" style="padding: 5px; margin-right: 10px;">
                <option value="">Select a class</option>
              </select>
              <span id="selectedClassPreview" style="display: inline-block; width: 20px; height: 20px; border: 2px solid #000; margin-left: 10px;"></span>
            </p>
          </div>
        </div>
        
        <!-- 
          INDIVIDUAL ANNOTATION MANAGEMENT SECTION
          This section displays detailed information for each individual annotation created.
          Each annotation gets its own card showing ID, class, color, comments, and visibility controls.
          Think of it like a detailed inventory list where each item has its own detailed record card.
        -->
        <div id="annotationManagement" style="margin-top: 20px; padding: 15px; border: 2px solid #ccc; border-radius: 5px; background-color: #f9f9f9;">
          <h3>Individual Annotations</h3>
          <p style="margin-bottom: 15px; color: #666; font-style: italic;">
            Each annotation you create will appear here with detailed controls and information.
          </p>
          
          <!-- Container for all individual annotation cards -->
          <div id="annotationsList" style="max-height: 400px; overflow-y: auto; border: 1px solid #ddd; border-radius: 3px; background: white; padding: 10px;">
            <!-- Individual annotation cards will be dynamically added here by JavaScript -->
            <div id="noAnnotationsMessage" style="text-align: center; color: #999; padding: 20px; font-style: italic;">
              No annotations created yet. Create an annotation by pressing 'n' and clicking on the video.
            </div>
          </div>
          
          <!-- Bulk Actions for Annotations -->
          <div id="bulkActions" style="margin-top: 15px; padding: 10px; border: 1px solid #ddd; border-radius: 3px; background: #f5f5f5;">
            <h4 style="margin: 0 0 10px 0;">Bulk Actions:</h4>
            <input type="button" id="showAllAnnotations" value="Show All" onclick="toggleAllAnnotationsVisibility(true)" style="margin-right: 10px; padding: 5px 10px; background: #4CAF50; color: white; border: none; border-radius: 3px; cursor: pointer;" />
            <input type="button" id="hideAllAnnotations" value="Hide All" onclick="toggleAllAnnotationsVisibility(false)" style="margin-right: 10px; padding: 5px 10px; background: #f44336; color: white; border: none; border-radius: 3px; cursor: pointer;" />
            <input type="button" id="deleteAllAnnotations" value="Delete All" onclick="deleteAllAnnotations()" style="padding: 5px 10px; background: #ff9800; color: white; border: none; border-radius: 3px; cursor: pointer;" />
          </div>
        </div>
      </li>
      <li>
        <!-- 
          STEP 6: GENERATE XML ANNOTATIONS
          After you've annotated your video (drawn boxes around objects), this step lets you
          save all that work as an XML file. Think of this like "Save As" in Microsoft Word -
          you're saving your work in a format that other programs can understand and use.
          
          XML (eXtensible Markup Language) is a structured way to store data that both humans
          and computers can read. It's like a very organized filing system for your annotations.
        -->
        <p><input type="button" id="generateXml" value="Generate" disabled="true" /> the -compatible XML annotations file.</p>
        <!-- This button starts disabled and becomes clickable once you have annotations to save -->
      </li>
      <li>
        <!-- 
          STEP 7: EXPORT OPTIONS
          This is like the "final product" section - after you've done all your annotation work,
          these buttons let you create different types of outputs from your work.
          
          Think of it like a restaurant kitchen where you can serve the same meal in different ways:
          - Export Video: Creates a new video with your boxes drawn on it (like subtitles burned into a movie)
          - Export Zip: Gives you individual image files with the boxes drawn on them
        -->
        <p><input type="button" id="exportVideo" class="export-video-button" value="Export Video" disabled="true" onclick="exportAnnotatedFramesAsVideo()" /> Export annotated frames as video.</p>
        <!-- onclick="exportAnnotatedFramesAsVideo()" tells the browser what function to run when clicked -->
        
        <p><input type="button" id="exportAnnotatedZip" class="export-annotated-zip-button" value="Export Annotated Frames Zip" disabled="true" onclick="exportAnnotatedFramesAsZip()" /> Export frames with bounding boxes as zip.</p>
        <!-- This creates a ZIP file containing individual frames with your annotations drawn on them -->
        
        <!-- 
          EXPORT PROGRESS INDICATOR
          This section shows the user how far along the export process is.
          It's hidden initially (display: none) and only appears when an export is running.
          Think of it like a progress bar when downloading a file - it keeps you informed!
        -->
        <div id="exportProgress" style="display: none;">
          <!-- 
            PROGRESS BAR ELEMENT
            This creates a visual progress bar that fills up as the export progresses.
            The "value" starts at 0 and "max" is 100, so it shows percentage completion.
          -->
          <progress id="exportProgressBar" value="0" max="100"></progress>
          <!-- This span will show the percentage as text next to the progress bar -->
          <span id="exportProgressText">0%</span>
        </div>
      </li>
    </ol>

    <!-- 
      JAVASCRIPT LIBRARY IMPORTS - THE BRAIN OF THE APPLICATION
      
      Think of these script tags like calling in different specialists to help with different tasks.
      Each JavaScript file is like hiring a professional contractor who specializes in one specific job.
      The order matters here - you need to lay the foundation before you can build the walls!
      
      These libraries handle complex tasks so the main application doesn't have to reinvent the wheel.
      It's like buying pre-made ingredients instead of making everything from scratch.
    -->

</style>
    <!-- 
      COMPATIBILITY LAYER
      This ensures the app works on older browsers that might not support newer features.
      Think of it like a translator that speaks both old and new computer languages.
    -->
    <!-- compatibility with older versions -->
    <script type="text/javascript" src="dist/compatibility.js"></script>
    
    <!-- 
      ZIP FILE HANDLING
      This library knows how to create, read, and extract ZIP files.
      Like having a friend who's really good at packing and unpacking suitcases efficiently.
    -->
    <!-- zip file handling -->
    <script type="text/javascript" src="dist/jszip.js"></script>
    
    <!-- 
      FILE DOWNLOADING CAPABILITY
      This enables the browser to let users download files they create.
      Think of it like a delivery service that can package up your work and send it to you.
    -->
    <!-- file downloading ig -->
    <script type="text/javascript" src="dist/StreamSaver.js"></script>
    
    <!-- 
      MODERN BROWSER FEATURE SUPPORT
      This adds support for newer features in older browsers.
      Like adding new apps to an older phone to make it work with modern services.
    -->
    <!-- deployment things -->
    <script type="text/javascript" src="dist/polyfill.js"></script>
    
    <!-- 
      COMPUTER VISION LIBRARY
      This handles the complex math for tracking objects in video frames.
      Think of it like having a very smart assistant who's excellent at spotting patterns and following moving objects.
    -->
    <!-- known library -->
    <script type="text/javascript" src="dist/jsfeat.js"></script>
    
    <!-- 
      GEOMETRIC TRANSFORMATION LIBRARY
      This helps with moving, rotating, and scaling objects accurately.
      Like having a geometry teacher who can calculate exactly how things should move.
    -->
    <script type="text/javascript" src="dist/nudged.js"></script>
    
    <!-- 
      LOCAL DATABASE STORAGE
      This allows the app to save data locally in the browser.
      Think of it like having a filing cabinet in your office that remembers your work even if you close the app.
    -->
    <script type="text/javascript" src="dist/pouchdb.min.js"></script>
    
    <!-- 
      JQUERY - THE SWISS ARMY KNIFE
      This is one of the most popular JavaScript libraries that makes it easier to:
      - Find and modify elements on the webpage
      - Handle user interactions (clicks, typing, etc.)
      - Create smooth animations
      Think of it like having a universal remote control that works with everything on your webpage.
    -->
    <script type="text/javascript" src="dist/jquery-1.12.4.js"></script>
    
    <!-- 
      JQUERY UI - USER INTERFACE ENHANCEMENTS
      This adds fancy interactive widgets like sliders, drag-and-drop, and dialogs.
      Think of it like upgrading from basic light switches to smart home controls.
    -->
    <script type="text/javascript" src="dist/jquery-ui.js"></script>
    
    <!-- 
      VIDEO FRAME EXTRACTION ENGINE
      This is the core engine that breaks videos apart into individual frames.
      Think of it like a machine that can take apart a flip-book and give you each page separately.
      
      IMPORTANT NOTE: There's a typo here! "src-=" should be "src=" 
      This might cause the script to not load properly. In a real project, this would be a bug to fix.
    -->
    <!-- frame extraction js framez.js -->
    <!-- <script type="text/javascript" src="dist/framez.js"></script> -->
     <script type="text/javascript">
      

        
              /* 
  FRAMEZ.JS - VIDEO ANNOTATION TOOL CORE ENGINE
  
  This file is like the brain of our video annotation application. Think of it like the engine
  of a car - it contains all the complex machinery that makes everything work, but users don't
  see it directly. They just interact with the steering wheel and pedals (the HTML interface).
  
  What this tool does:
  1. Takes a video file and breaks it into individual pictures (frames) - like taking apart a flip-book
  2. Lets users draw boxes around objects in those pictures
  3. Uses computer vision magic to automatically track those boxes as objects move between frames
  4. Saves all that work so users can download it or continue later
  
  Think of it like having a super-smart assistant that can:
  - Take screenshots of every moment in a video
  - Remember where you drew boxes around things
  - Predict where those things will be in the next frame
  - Keep track of everything so you don't lose your work
*/

// this is the main entry point for the application  
"use strict"; // This tells JavaScript to be extra careful about catching programming mistakes

          /*
            FRAMES MANAGER CLASS - THE VIDEO FRAME COORDINATOR
            
            Think of this class like a librarian who manages a collection of photos (video frames).
            The librarian keeps track of:
            - How many photos are in the collection
            - How to get any specific photo when someone asks for it
            - Who to notify when the collection changes (like getting a new set of photos)
            
            A "class" in programming is like a blueprint for creating objects. It's like having
            a cookie cutter - you can use it to make many cookies (objects) that all have the
            same shape but might have different decorations.
          */
          class FramesManager {
            constructor() {
              /*
                The constructor is like the "birth certificate" of an object - it sets up
                the initial state when a new FramesManager is created. Think of it like
                setting up a new filing cabinet with empty folders.
              */
              this.frames = {
                totalFrames: () => { return 0; } // Start with zero frames, like an empty photo album
              };
              this.onReset = []; // List of functions to call when we get new frames (like a notification list)
            }

            set(frames) {
              /*
                This method is like replacing all the photos in our album with a new set.
                When this happens, we need to tell everyone who was interested in the old photos
                that we now have new ones. It's like sending a group text saying "Hey, I got new photos!"
              */
              this.frames = frames; // Replace our current frame collection with the new one
              
              // Notify all interested parties that we have new frames
              for (let i = 0; i < this.onReset.length; i++) {
                this.onReset[i](); // Call each notification function in our list
              }
            }
          }

          /*
            BLOB TO IMAGE CONVERTER FUNCTION
            
            This function is like a photo developer in the old days. When you took film to be developed,
            they would take the raw film data and turn it into actual pictures you could look at.
            
            In our case, we have "blob" data (Binary Large Object - basically a chunk of file data)
            and we need to turn it into an actual image that can be displayed on screen.
            
            A "Promise" is like making a reservation at a restaurant - you don't get your table
            immediately, but you get a promise that you'll get it eventually. The function returns
            a promise because converting blob data takes time, and we don't want to freeze the
            entire application while waiting.
          */
          function blobToImage(blob) {
            return new Promise((result, _) => {
              /*
                Create a new Image object - think of this like getting a blank picture frame
                that we're going to put a photo into.
              */
              let img = new Image();
              
              /*
                Set up what happens when the image finishes loading. This is like saying
                "When the photo is fully developed and ready, do this..."
              */
              img.onload = function() {
                result(img); // Tell the Promise "We're done! Here's your image!"
                
                /*
                  Clean up the temporary URL we created. Think of this like throwing away
                  the negative after you've printed your photo - we don't need it anymore
                  and it takes up memory.
                */
                URL.revokeObjectURL(this.src);
              };
              
              /*
                Create a temporary URL from the blob data and tell the image to load from it.
                This is like creating a temporary address where the browser can find our image data.
              */
              img.src = URL.createObjectURL(blob);
            });
          }

          /**
           * VIDEO FRAME EXTRACTION FUNCTION - THE FRAME RIPPER
           * 
           * This is like having a super-fast camera operator who can watch a movie and take
           * a perfect screenshot of every single frame. Imagine watching a flip-book and
           * carefully removing each page to create a stack of individual pictures.
           * 
           * The function takes a video file and breaks it down into individual frames (pictures),
           * then stores each frame in a database so we can access them later.
           * 
           * Parameters:
           * - config: Settings that control how the extraction works (like quality, speed, etc.)
           * - file: The video file to extract frames from
           * - progress: A function to call with updates on how the extraction is going
           */
          function extractFramesFromVideo(config, file, progress) {
            /*
              Set up all our variables - think of this like laying out all your tools
              before starting a big project. We're preparing everything we'll need.
            */
            let resolve = null; // Function to call when we're completely done
            let db = null; // Database to store our extracted frames
            let video = document.createElement('video'); // Create an invisible video player
            let canvas = document.createElement('canvas'); // Create an invisible drawing surface
            let ctx = canvas.getContext('2d'); // Get the "paintbrush" for our canvas
            let dimensionsInitialized = false; // Have we figured out the video size yet?
            let totalFrames = 0; // How many frames we've found so far
            let processedFrames = 0; // How many frames we've successfully saved
            let lastApproxFrame = -1; // The last frame number we processed (to avoid duplicates)
            let lastProgressFrame = -1; // The last frame we reported progress for
            let attachmentName = 'img' + config.imageExtension; // What to name each frame file

            /*
              Return a Promise - this is like giving someone a receipt that says
              "Your order is being prepared, we'll call you when it's ready"
            */
            return new Promise((_resolve, _) => {
              resolve = _resolve; // Store the "call when ready" function

              /*
                Set up our database. We destroy any existing database first (like clearing
                out an old photo album) and then create a fresh one.
              */
              let dbName = 'vatic_js'; // Name of our database
              db = new PouchDB(dbName).destroy().then(() => {
                db = new PouchDB(dbName); // Create a fresh database

                /*
                  Configure our invisible video player. Think of this like setting up
                  a DVD player with specific settings before pressing play.
                */
                video.autoplay = false; // Don't start playing automatically
                video.muted = true; // No sound (we only care about the pictures)
                video.loop = false; // Don't repeat when it reaches the end
                video.playbackRate = config.playbackRate; // How fast to play (might be faster than normal)
                video.src = URL.createObjectURL(file); // Tell the video player what file to load
                
                /*
                  Start our frame-by-frame processing. This sets up a loop that will run
                  continuously, checking if there's a new frame to capture.
                */
                compatibility.requestAnimationFrame(onBrowserAnimationFrame);
                video.play(); // Start the video playing
              });
            });

            /*
              MAIN FRAME PROCESSING LOOP
              
              This function is like a security guard who checks every few milliseconds:
              "Is there a new frame ready? Should I take a screenshot?"
              
              It runs continuously while the video plays, capturing frames and saving them.
              Think of it like having a robot that sits next to a TV and takes a photo
              every time the picture changes.
            */
            function onBrowserAnimationFrame() {
              /*
                Check if we're done with the entire video. This is like checking if
                we've reached the end of our flip-book and all pages are saved.
              */
              if (dimensionsInitialized && video.ended) {
                if (processedFrames == totalFrames) {
                  videoEnded(); // We're completely done!
                }
                return; // Exit this function
              }

              /*
                Schedule this function to run again on the next animation frame.
                This creates a continuous loop - like setting an alarm that goes off
                60 times per second to check for new frames.
              */
              compatibility.requestAnimationFrame(onBrowserAnimationFrame);

              /*
                Check if the video has enough data loaded to show a frame.
                It's like checking if a streaming video has buffered enough to display the picture.
                If not, we'll try again on the next loop.
              */
              if (video.readyState !== video.HAVE_CURRENT_DATA &&
                  video.readyState !== video.HAVE_FUTURE_DATA &&
                  video.readyState !== video.HAVE_ENOUGH_DATA) {
                return; // Not ready yet, try again next time
              }

              /*
                Calculate which frame number we should be at based on the current time.
                This is like looking at a stopwatch and calculating "At 2.5 seconds into
                a 30fps video, we should be at frame 75"
              */
              let currentApproxFrame = Math.round(video.currentTime * config.fps);
              
              /*
                Only process if this is a new frame (avoid processing the same frame twice).
                It's like only taking a photo when the TV actually shows a new picture.
              */
              if (currentApproxFrame != lastApproxFrame) {
                lastApproxFrame = currentApproxFrame; // Remember this frame number
                let frameNumber = totalFrames; // Assign a sequential number to this frame
                totalFrames++; // Increment our frame counter

                /*
                  If this is our first frame, figure out the video dimensions and set up
                  our canvas to match. It's like measuring a picture before choosing a frame.
                */
                if (!dimensionsInitialized) {
                  dimensionsInitialized = true;
                  canvas.width = video.videoWidth; // Match the video's width
                  canvas.height = video.videoHeight; // Match the video's height
                }

                /*
                  Draw the current video frame onto our canvas. This is like taking a
                  screenshot of the video at this exact moment.
                */
                ctx.drawImage(video, 0, 0);
                
                /*
                  Convert the canvas drawing to a blob (file data) and save it to our database.
                  This is like taking our screenshot and saving it as a JPEG file.
                */
                canvas.toBlob(
                  (blob) => {
                    /*
                      Save this frame to our database with a unique ID.
                      It's like putting a photo in a filing cabinet with a label.
                    */
                    db.putAttachment(frameNumber.toString(), attachmentName, blob, config.imageMimeType).then((doc) => {
                      processedFrames++; // One more frame successfully saved!

                      /*
                        Report progress to the user (but not for every single frame,
                        as that would be too much information). It's like giving updates
                        every 10% instead of every single step.
                      */
                      if (frameNumber > lastProgressFrame) {
                        lastProgressFrame = frameNumber;
                        progress(video.currentTime / video.duration, processedFrames, blob);
                      }

                      /*
                        Check if we're completely done (video ended AND all frames saved).
                        This ensures we don't finish before all frames are actually saved to the database.
                      */
                      if (video.ended && processedFrames == totalFrames) {
                        videoEnded();
                      }
                    });
                  },
                  config.imageMimeType); // Specify what type of image file to create (JPEG, PNG, etc.)
              }
            }

            /*
              CLEANUP AND COMPLETION FUNCTION
              
              This function is called when we're completely done extracting all frames.
              It's like cleaning up your workspace after finishing a big project and
              delivering the final result.
            */
            function videoEnded() {
              /*
                Clean up the video resource. We check if there's still a source URL
                to avoid cleaning up twice (which could cause errors).
              */
              if (video.src != '') {
                URL.revokeObjectURL(video.src); // Free up memory used by the video URL
                video.src = ''; // Clear the video source

                /*
                  Return our final result - an object that provides access to all the frames
                  we extracted. This is like handing over a photo album with two capabilities:
                  1. Tell you how many photos are in it
                  2. Give you any specific photo when you ask for it by number
                */
                resolve({
                  totalFrames: () => { return totalFrames; }, // Function to get total frame count
                  getFrame: (frameNumber) => {
                    /*
                      Function to retrieve a specific frame from our database.
                      It's like asking "Can I see photo number 42?" and getting that exact photo.
                    */
                    return db.getAttachment(frameNumber.toString(), attachmentName);
                  }
                });
              }
            }
          }

          /**
           * ZIP FILE FRAME EXTRACTION FUNCTION - THE ARCHIVE UNPACKER
           * 
           * This function is like having a helper who can open a suitcase full of photos
           * that were previously packed up. Instead of extracting frames from a video,
           * this extracts frames from a ZIP file that was created in a previous session.
           * 
           * Think of it like this: Yesterday you took apart a flip-book and put all the
           * pages in a folder. Today you want to work with those pages again, so you
           * open the folder and organize them so you can use them.
           * 
           * Parameters:
           * - config: Settings for how to handle the images
           * - file: The ZIP file containing previously extracted frames
           */
          function extractFramesFromZip(config, file) {
            return new Promise((resolve, _) => {
              /*
                Use the JSZip library to open and read the ZIP file.
                This is like using a special tool to open a compressed folder.
              */
              JSZip
                .loadAsync(file) // Open the ZIP file (this takes time, so it's asynchronous)
                .then((zip) => {
                  /*
                    Count how many files are in the ZIP. Each file should be one frame.
                    This is like counting how many photos are in the folder.
                  */
                  let totalFrames = 0;
                  for (const file in zip.files) {
                    if (zip.files.hasOwnProperty(file)) { // Make sure this is actually a file in the ZIP
                      totalFrames++; // Count each file
                    }
                  }
                
                  /*
                    Return an object that provides access to the frames, just like
                    the video extraction function does. This gives the same interface
                    whether frames came from a video or a ZIP file.
                  */
                  resolve({
                    totalFrames: () => { return totalFrames; }, // Function to get total count
                    getFrame: (frameNumber) => {
                      /*
                        Function to get a specific frame from the ZIP file.
                        This is more complex than the database version because we need to
                        find the right file in the ZIP and convert it to the right format.
                      */
                      return new Promise((resolve, _) => {
                        /*
                          Safety check: make sure the requested frame number is valid.
                          It's like checking "Do we actually have a photo number 42?"
                        */
                        if (frameNumber < 0 || frameNumber > totalFrames) {
                          throw new Error(`Invalid frameNumber in getFrame(). frameNumber is ${frameNumber} but there are ${totalFrames}.`);
                        }
                        
                        /*
                          Find the file in the ZIP that corresponds to this frame number.
                          ZIP files don't guarantee order, so we use the frame number as an index
                          into the list of file names.
                        */
                        const key = Object.keys(zip.files)[frameNumber]; // Get the filename
                        const file = zip.files[key]; // Get the actual file object

                        /*
                          Extract the file data and convert it to a blob (the format our
                          application expects). This is like taking a photo out of an envelope
                          and making sure it's in the right format to display.
                        */
                        file
                          .async('arraybuffer') // Get the raw file data
                          .then((content) => {
                            /*
                              Create a blob from the raw data. A blob is like a container
                              that holds file data in a format the browser can work with.
                            */
                            let blob = new Blob([ content ], {type: config.imageMimeType});
                            resolve(blob); // Return the blob to whoever asked for this frame
                          });
                      });
                    }
                  });
                });
            });
          }

          /**
           * OPTICAL FLOW CLASS - THE MOTION TRACKER
           * 
           * This is like having a super-smart detective who can look at two photos taken
           * one second apart and figure out exactly how everything moved between them.
           * 
           * Imagine you have two pictures of a busy street - one taken at 3:00 PM and
           * another at 3:01 PM. This class can look at both pictures and tell you:
           * "The red car moved 15 pixels to the right, the person walking moved 8 pixels
           * down and 3 pixels left, etc."
           * 
           * This is crucial for our annotation tool because when a user draws a box around
           * a car in frame 1, we want to automatically predict where that car will be in
           * frame 2, so the user doesn't have to redraw the box every single time.
           */
          class OpticalFlow {
            constructor() {
              /*
                Set up the initial state. Think of this like preparing a detective's workspace
                with file folders for "previous case" and "current case"
              */
              this.isInitialized = false; // Have we processed our first frame yet?
              
              /*
                Create "image pyramids" - these are like having multiple versions of the same
                photo at different zoom levels. It's like having the same picture in sizes:
                giant poster, regular photo, and thumbnail. This helps the algorithm work
                better because it can track big movements in the small images and fine
                movements in the large images.
              */
              this.previousPyramid = new jsfeat.pyramid_t(3); // 3 levels of zoom
              this.currentPyramid = new jsfeat.pyramid_t(3);   // 3 levels of zoom
            }

            /*
              INITIALIZATION FUNCTION - SETTING UP THE DETECTIVE
              
              This prepares our optical flow algorithm with the first frame.
              It's like showing a detective the "before" photo so they can later
              compare it with the "after" photo.
            */
            init(imageData) {
              /*
                Allocate memory for our image pyramids based on the image size.
                This is like getting the right size folders for our photos.
                
                jsfeat.U8_t | jsfeat.C1_t means "8-bit unsigned integers, 1 channel"
                In simple terms: grayscale images where each pixel is a number from 0-255
              */
              this.previousPyramid.allocate(imageData.width, imageData.height, jsfeat.U8_t | jsfeat.C1_t);
              this.currentPyramid.allocate(imageData.width, imageData.height, jsfeat.U8_t | jsfeat.C1_t);
              
              /*
                Convert the color image to grayscale and store it in our previous pyramid.
                Optical flow works better with grayscale because it focuses on brightness
                patterns rather than colors. It's like a detective focusing on shapes and
                shadows rather than colors when tracking movement.
              */
              jsfeat.imgproc.grayscale(imageData.data, imageData.width, imageData.height, this.previousPyramid.data[0]);
              
              /*
                Build the pyramid (create the different zoom levels).
                This creates thumbnail and medium-sized versions of our image.
              */
              this.previousPyramid.build(this.previousPyramid.data[0]);
              
              this.isInitialized = true; // We're now ready to track motion!
            }

            /*
              RESET FUNCTION - STARTING FRESH
              
              This is like telling our detective "Forget everything you knew before,
              we're starting a completely new case." Used when we load a new video
              or jump to a different part of the video.
            */
            reset() {
              this.isInitialized = false;
            }

            /*
              MAIN TRACKING FUNCTION - THE MOTION DETECTOR
              
              This is where the magic happens! This function takes the current frame and
              a list of bounding boxes, then figures out where those boxes should be moved
              to match how objects have moved between frames.
              
              Think of it like this: You drew boxes around cars in yesterday's traffic photo.
              Today you have a new traffic photo from the same intersection. This function
              looks at both photos and says "The car that was in box 1 has moved here,
              the car in box 2 has moved there," etc.
            */
            track(imageData, bboxes) {
              /*
                Safety check: Make sure we've been initialized with a previous frame.
                It's like making sure the detective has seen the "before" photo before
                trying to compare it with the "after" photo.
              */
              if (!this.isInitialized) {
                throw 'not initialized';
              }

              /*
                Process the new frame: convert to grayscale and build the pyramid.
                This prepares our "after" photo for comparison.
              */
              jsfeat.imgproc.grayscale(imageData.data, imageData.width, imageData.height, this.currentPyramid.data[0]);
              this.currentPyramid.build(this.currentPyramid.data[0]);

              // TODO: Move all configuration to config
              let bboxBorderWidth = 1; // Small border around bounding boxes

              /*
                SET UP TRACKING POINTS
                
                Instead of tracking entire boxes, we track many small points within each box.
                Think of it like putting a grid of tiny sensors inside each box - if most
                of the sensors move in the same direction, we know the whole object moved
                that way.
                
                We use an 11x11 grid of points for each bounding box (121 points total per box).
                It's like putting 121 tiny GPS trackers inside each box to see how they move.
              */
              let pointsPerDimension = 11; // 11 points along each edge of the box
              let pointsPerObject = pointsPerDimension * pointsPerDimension; // 11x11 = 121 points per box
              let pointsCountUpperBound = bboxes.length * pointsPerObject; // Maximum possible points
              
              /*
                Create arrays to store our tracking data:
                - pointsStatus: Did each point track successfully? (1 = success, 0 = failed)
                - previousPoints: Where each point was in the previous frame
                - currentPoints: Where each point ended up in the current frame
              */
              let pointsStatus = new Uint8Array(pointsCountUpperBound);      // Success/failure for each point
              let previousPoints = new Float32Array(pointsCountUpperBound * 2); // X,Y coordinates in previous frame
              let currentPoints = new Float32Array(pointsCountUpperBound * 2);  // X,Y coordinates in current frame

              /*
                POPULATE TRACKING POINTS
                
                For each bounding box, create a grid of points evenly distributed within it.
                Think of it like placing thumbtacks in a grid pattern within each box.
              */
              let pointsCount = 0;
              for (let i = 0, n = 0; i < bboxes.length; i++) {
                let bbox = bboxes[i];
                if (bbox != null) { // Only process boxes that actually exist
                  /*
                    Create an 11x11 grid of points within this bounding box.
                    Each point is placed at a specific fraction of the box's width and height.
                  */
                  for (let x = 0; x < pointsPerDimension; x++) {
                    for (let y = 0; y < pointsPerDimension; y++) {
                      /*
                        Calculate the exact position of this point within the bounding box.
                        The formula spreads points evenly across the box from edge to edge.
                      */
                      previousPoints[pointsCount*2] = bbox.x + x * (bbox.width / (pointsPerDimension - 1));      // X coordinate
                      previousPoints[pointsCount*2 + 1] = bbox.y + y * (bbox.height / (pointsPerDimension - 1)); // Y coordinate
                      pointsCount++; // Count how many points we've created
                    }
                  }
                }
              }
              
              /*
                Safety check: Make sure we have at least some points to track.
                If there are no bounding boxes or all boxes are null, there's nothing to track.
              */
              if (pointsCount == 0) {
                throw 'no points to track';
              }

              /*
                RUN THE OPTICAL FLOW ALGORITHM
                
                This is the actual "magic" - the Lucas-Kanade optical flow algorithm.
                It analyzes the brightness patterns around each point in both frames
                and calculates where each point most likely moved to.
                
                The parameters (30, 30, 0.01, 0.001) are fine-tuning values that control
                how the algorithm works - like adjusting the sensitivity of our motion detector.
              */
              jsfeat.optical_flow_lk.track(
                this.previousPyramid,    // Previous frame (where points started)
                this.currentPyramid,     // Current frame (where points ended up)
                previousPoints,          // Starting positions of all points
                currentPoints,           // Where the algorithm thinks points moved to
                pointsCount,             // How many points we're tracking
                30,                      // Window size for analysis
                30,                      // Number of iterations
                pointsStatus,            // Output: which points were tracked successfully
                0.01,                    // Convergence threshold
                0.001                    // Minimum eigenvalue threshold
              );

              /*
                CALCULATE NEW BOUNDING BOX POSITIONS
                
                Now we have information about how individual points moved, but we need to
                figure out how to move entire bounding boxes. This is like having data
                about how 121 individual sensors moved, and using that to determine how
                the whole object moved.
              */
              let newBboxes = []; // Array to store the updated bounding box positions
              let p = 0; // Index to track which point we're currently processing
              
              /*
                Process each bounding box one at a time
              */
              for (let i = 0; i < bboxes.length; i++) {
                let bbox = bboxes[i]; // Get the original bounding box
                let newBbox = null;   // Start with no new position (will be calculated)

                if (bbox != null) {   // Only process boxes that actually exist
                  /*
                    Collect the movement data for all points that belong to this bounding box.
                    We separate the points into "before" and "after" positions, but only
                    include points that were successfully tracked.
                  */
                  let before = []; // Where points were in the previous frame
                  let after = [];  // Where points ended up in the current frame

                  /*
                    Go through all points for this bounding box (121 points in an 11x11 grid)
                  */
                  for (let j = 0; j < pointsPerObject; j++, p++) {
                    /*
                      Only use points that were successfully tracked. Some points might fail
                      if they moved out of frame or if the tracking algorithm lost them.
                    */
                    if (pointsStatus[p] == 1) { // 1 means "successfully tracked"
                      let x = p * 2;     // X coordinate index (points are stored as [x1,y1,x2,y2,...])
                      let y = x + 1;     // Y coordinate index

                      /*
                        Add this point's before/after positions to our collections
                      */
                      before.push([previousPoints[x], previousPoints[y]]); // Where it was
                      after.push([currentPoints[x], currentPoints[y]]);   // Where it went
                    }
                  }

                  /*
                    If we have at least some successfully tracked points, calculate the
                    overall movement of the bounding box.
                  */
                  if (before.length > 0) {
                    /*
                      Use the "nudged" library to calculate the best transformation that
                      maps the "before" points to the "after" points. We specify 'T' which
                      means "translation only" (just movement, no rotation or scaling).
                      
                      This is like saying "Look at all these point movements and figure out
                      the single direction and distance that best explains how they all moved."
                    */
                    let diff = nudged.estimate('T', before, after);
                    let translation = diff.getTranslation(); // Get the movement vector [deltaX, deltaY]

                    /*
                      Calculate the new bounding box position by applying the movement.
                      We also add safety checks to make sure the box doesn't go outside
                      the image boundaries.
                    */
                    let minX = Math.max(Math.round(bbox.x + translation[0]), 0); // New left edge (can't be negative)
                    let minY = Math.max(Math.round(bbox.y + translation[1]), 0); // New top edge (can't be negative)
                    let maxX = Math.min(Math.round(bbox.x + bbox.width + translation[0]), imageData.width - 2*bboxBorderWidth);   // New right edge
                    let maxY = Math.min(Math.round(bbox.y + bbox.height + translation[1]), imageData.height - 2*bboxBorderWidth); // New bottom edge
                    
                    /*
                      Calculate the new width and height based on the constrained edges
                    */
                    let newWidth = maxX - minX;
                    let newHeight = maxY - minY;

                    /*
                      Only create a new bounding box if it has positive width and height.
                      If the object moved completely out of frame, we'll get zero or negative
                      dimensions, which means we should mark this object as invisible.
                    */
                    if (newWidth > 0 && newHeight > 0) {
                      newBbox = new BoundingBox(minX, minY, newWidth, newHeight);
                    }
                  }
                }

                /*
                  Add the new bounding box (or null if tracking failed) to our results.
                  This maintains the same order as the input bboxes array.
                */
                newBboxes.push(newBbox);
              }

              /*
                PREPARE FOR NEXT FRAME
                
                Swap the pyramids so that what was "current" becomes "previous" for the next
                tracking operation. This is like moving today's photo to the "yesterday" folder
                and getting ready for tomorrow's photo.
                
                We reuse the old pyramid object to save memory - it's like reusing a folder
                instead of creating a new one each time.
              */
              let oldPyramid = this.previousPyramid;
              this.previousPyramid = this.currentPyramid; // Current becomes previous
              this.currentPyramid = oldPyramid;           // Reuse the old previous as new current

              return newBboxes; // Return the updated bounding box positions
            }
          };

          /**
           * BOUNDING BOX CLASS - THE RECTANGLE CONTAINER
           * 
           * This is a simple class that represents a rectangular box drawn around an object.
           * Think of it like a picture frame or a highlighter rectangle that marks where
           * an object is located in an image.
           * 
           * It stores four numbers that completely describe a rectangle:
           * - x: How far from the left edge of the image (like "5 inches from the left")
           * - y: How far from the top edge of the image (like "3 inches from the top")
           * - width: How wide the rectangle is (like "the frame is 4 inches wide")
           * - height: How tall the rectangle is (like "the frame is 6 inches tall")
           * 
           * With these four numbers, you can draw the exact same rectangle anywhere!
           */
          class BoundingBox {
            constructor(x, y, width, height) {
              this.x = x;           // Left edge position
              this.y = y;           // Top edge position  
              this.width = width;   // How wide the box is
              this.height = height; // How tall the box is
            }
          }

          /**
           * ANNOTATED FRAME CLASS - THE PHOTO WITH NOTES
           * 
           * This class represents a single frame (image) from a video along with information
           * about what's in that frame. Think of it like a photo with a sticky note attached
           * that says "There's a car at this location in this picture."
           * 
           * Each AnnotatedFrame contains:
           * - frameNumber: Which frame this is (like "photo #42 out of 1000")
           * - bbox: Where the object is in this frame (the rectangular box around it)
           * - isGroundTruth: Did a human draw this box, or did the computer guess it?
           * 
           * The "isGroundTruth" concept is important: 
           * - Ground truth = A human carefully drew this box (very accurate)
           * - Not ground truth = The computer predicted this box using optical flow (good guess, but might be wrong)
           */
          class AnnotatedFrame {
            constructor(frameNumber, bbox, isGroundTruth) {
              this.frameNumber = frameNumber;     // Which frame number this annotation belongs to
              this.bbox = bbox;                   // The bounding box (can be null if object is not visible)
              this.isGroundTruth = isGroundTruth; // True if human-drawn, false if computer-predicted
            }

            /*
              VISIBILITY CHECK FUNCTION
              
              This is a helper function that answers the question "Can we see the object in this frame?"
              An object is visible if it has a bounding box. If bbox is null, it means the object
              is not visible in this frame (maybe it went off-screen or behind something).
              
              Think of it like asking "Is there a sticky note on this photo?" If yes, the object
              is visible. If no sticky note, the object is not visible in this frame.
            */
            isVisible() {
              return this.bbox != null; // null means "not visible", anything else means "visible"
            }
          }

          /**
           * ANNOTATED OBJECT CLASS - THE COMPLETE OBJECT STORY
           * 
           * This class represents one object (like "the red car" or "the walking person")
           * throughout the entire video. Think of it like a photo album dedicated to just
           * one person - it contains pictures of that person from different events, but
           * they're all organized together.
           * 
           * An AnnotatedObject contains a collection of AnnotatedFrames, each showing where
           * that specific object was in different frames of the video. So if you're tracking
           * a car through a 100-frame video, this object might contain 100 AnnotatedFrames
           * showing the car's position in each frame.
           * 
           * The frames array is kept sorted by frame number, like organizing photos by date.
           */
          class AnnotatedObject {
            constructor() {
              this.frames = []; // Array of AnnotatedFrame objects, sorted by frame number
            }

            /*
              ADD FRAME FUNCTION - ADDING A NEW PHOTO TO THE ALBUM
              
              This function adds a new AnnotatedFrame to this object's collection.
              It's smart about where to put it and handles several tricky situations:
              
              1. If the frame already exists, replace it (like updating a photo)
              2. Insert frames in the right order (keep the album organized by date)
              3. Remove computer-predicted frames that need to be recalculated
              4. Make sure there's always a frame at the beginning (frame 0)
            */
            add(frame) {
              /*
                Search through existing frames to find where this new frame should go.
                We want to keep frames sorted by frame number.
              */
              for (let i = 0; i < this.frames.length; i++) {
                /*
                  Case 1: We found a frame with the same frame number.
                  Replace the existing frame with the new one and clean up any
                  computer-predicted frames that come after it.
                */
                if (this.frames[i].frameNumber == frame.frameNumber) {
                  this.frames[i] = frame; // Replace the existing frame
                  this.removeFramesToBeRecomputedFrom(i + 1); // Clean up predictions after this frame
                  return; // We're done
                } 
                /*
                  Case 2: We found where the new frame should be inserted.
                  Insert it here and clean up any predictions that come after it.
                */
                else if (this.frames[i].frameNumber > frame.frameNumber) {
                  this.frames.splice(i, 0, frame); // Insert the frame at position i
                  this.removeFramesToBeRecomputedFrom(i + 1); // Clean up predictions after this frame
                  this.injectInvisibleFrameAtOrigin(); // Make sure we have a frame 0
                  return; // We're done
                }
              }

              /*
                Case 3: The new frame has a higher frame number than all existing frames.
                Add it to the end of the array.
              */
              this.frames.push(frame);
              this.injectInvisibleFrameAtOrigin(); // Make sure we have a frame 0
            }

            /*
              GET FRAME FUNCTION - FINDING A SPECIFIC PHOTO
              
              This function looks through the frames array to find the frame with a
              specific frame number. It's like looking through a photo album to find
              "the photo from day 15 of our vacation."
              
              Returns the AnnotatedFrame if found, or null if not found.
            */
            get(frameNumber) {
              /*
                Search through all frames in order. Since they're sorted by frame number,
                we can stop searching as soon as we pass the target frame number.
              */
              for (let i = 0; i < this.frames.length; i++) {
                let currentFrame = this.frames[i];
                
                /*
                  If we've gone past the target frame number, it means the frame
                  doesn't exist in our collection.
                */
                if (currentFrame.frameNumber > frameNumber) {
                  break; // Stop searching
                }

                /*
                  Found the exact frame we were looking for!
                */
                if (currentFrame.frameNumber == frameNumber) {
                  return currentFrame;
                }
              }

              return null; // Frame not found
            }

            /*
              CLEANUP FUNCTION - REMOVING OUTDATED COMPUTER PREDICTIONS
              
              When a human draws a new bounding box, any computer-predicted boxes that come
              after it become invalid and need to be removed. This is because the computer's
              predictions were based on the old human input, not the new one.
              
              Think of it like this: You're giving directions to a friend, and halfway through
              you realize you made a mistake in step 3. You need to throw away all the steps
              that came after the mistake and recalculate them based on the corrected step 3.
              
              This function removes all non-ground-truth frames starting from a given position
              until it hits either the end of the array or another ground-truth frame.
            */
            removeFramesToBeRecomputedFrom(frameNumber) {
              let count = 0; // Count how many frames to remove
              
              /*
                Look at frames starting from frameNumber and count how many consecutive
                non-ground-truth frames there are.
              */
              for (let i = frameNumber; i < this.frames.length; i++) {
                if (this.frames[i].isGroundTruth) {
                  break; // Stop when we hit a human-drawn frame
                }
                count++; // This frame needs to be removed
              }
              
              /*
                Remove the outdated computer-predicted frames.
                splice(start, count) removes 'count' elements starting at position 'start'
              */
              if (count > 0) {
                this.frames.splice(frameNumber, count);
              }
            }

            /*
              ORIGIN FRAME INJECTION - ENSURING A STARTING POINT
              
              This function ensures that every object has a frame at position 0 (the very
              beginning of the video). If the first human annotation was at frame 50,
              we still need to know where the object was at frame 0 (even if it wasn't visible).
              
              This is like making sure every story has a clear beginning, even if the
              interesting part doesn't start until later. We add an "invisible" frame
              at the beginning that says "this object wasn't visible yet."
            */
            injectInvisibleFrameAtOrigin() {
              /*
                Check if we need to add a frame at position 0:
                - If there are no frames at all, OR
                - If the first frame is not at position 0
              */
              if (this.frames.length == 0 || this.frames[0].frameNumber > 0) {
                /*
                  Insert an invisible frame at the beginning.
                  new AnnotatedFrame(0, null, false) means:
                  - Frame number 0
                  - No bounding box (null = invisible)
                  - Not ground truth (computer-generated default)
                */
                this.frames.splice(0, 0, new AnnotatedFrame(0, null, false));
              }
            }
          }

          /**
           * ANNOTATED OBJECTS TRACKER CLASS - THE MASTER COORDINATOR
           * 
           * This is like having a super-smart film director who can keep track of multiple
           * actors (objects) throughout an entire movie (video). The director knows:
           * - Where each actor is in each scene (frame)
           * - How to predict where actors will be in upcoming scenes
           * - How to fill in missing information when an actor moves between scenes
           * 
           * This class coordinates all the different parts:
           * - Manages multiple AnnotatedObjects (like managing multiple actors)
           * - Uses OpticalFlow to predict movements
           * - Provides frames with all objects positioned correctly
           */
          class AnnotatedObjectsTracker {
            constructor(framesManager) {
              /*
                Set up the tracker with connections to other parts of the system
              */
              this.framesManager = framesManager;   // Connection to the frame storage system
              this.annotatedObjects = [];          // List of all objects we're tracking
              this.opticalFlow = new OpticalFlow(); // The motion detection system
              this.lastFrame = -1;                 // Keep track of which frame we processed last
              this.ctx = document.createElement('canvas').getContext('2d'); // Canvas for image processing

              /*
                Register a callback to reset our tracker when new frames are loaded.
                This is like telling the director "When we start filming a new movie,
                forget everything about the previous movie and start fresh."
              */
              this.framesManager.onReset.push(() => {
                this.annotatedObjects = []; // Clear all tracked objects
                this.lastFrame = -1;        // Reset frame tracking
              });
            }

            /*
              GET FRAME WITH OBJECTS - THE MAIN DELIVERY FUNCTION
              
              This is the main function that other parts of the application call when they
              want to see a specific frame with all the objects positioned correctly.
              
              It's like asking the director: "Can you show me what scene 42 looks like,
              with all the actors in their correct positions?"
              
              The function handles the complex logic of:
              1. Finding a good starting point (a frame where we know all object positions)
              2. Using optical flow to track objects from that starting point to the target frame
              3. Returning the final result with the image and all object positions
            */
            getFrameWithObjects(frameNumber) {
              return new Promise((resolve, _) => {
                /*
                  Find the best starting frame for tracking. We need a frame where we
                  have reliable position data for all objects (either human-annotated
                  or previously computed).
                */
                let i = this.startFrame(frameNumber);

                /*
                  TRACKING LOOP FUNCTION
                  
                  This inner function creates a loop that tracks objects frame by frame
                  from the starting frame to the target frame. It's like following
                  the actors scene by scene until we reach the scene we want.
                */
                let trackNextFrame = () => {
                  /*
                    Track objects for frame 'i' (this includes optical flow calculations
                    if needed, or just retrieval of existing data if it's already known)
                  */
                  this.track(i).then((frameWithObjects) => {
                    /*
                      Check if we've reached our target frame
                    */
                    if (i == frameNumber) {
                      resolve(frameWithObjects); // We're done! Return the result
                    } else {
                      /*
                        Not there yet - move to the next frame and continue tracking
                      */
                      i++;
                      trackNextFrame(); // Recursive call to continue the loop
                    }
                  });
                };

                trackNextFrame(); // Start the tracking loop
              });
            }

            /*
              START FRAME FINDER - FINDING A RELIABLE STARTING POINT
              
              This function works backwards from the target frame to find a frame where
              we have reliable position data for ALL tracked objects. It's like working
              backwards through a story to find the last point where we knew where
              everyone was located.
              
              Why do we need this? Because optical flow tracking works by comparing
              consecutive frames. If we want to know where objects are in frame 50,
              but we only have human annotations for frames 10 and 60, we need to
              start tracking from frame 10 and work our way up to frame 50.
            */
            startFrame(frameNumber) {
              /*
                Work backwards from the target frame, checking each frame to see if
                we have position data for all objects.
              */
              for (; frameNumber >= 0; frameNumber--) {
                let allObjectsHaveData = true; // Assume we have data for all objects

                /*
                  Check each tracked object to see if it has data for this frame
                */
                for (let i = 0; i < this.annotatedObjects.length; i++) {
                  let annotatedObject = this.annotatedObjects[i];
                  if (annotatedObject.get(frameNumber) == null) {
                    allObjectsHaveData = false; // Found an object with missing data
                    break; // No need to check the rest
                  }
                }

                /*
                  If all objects have data for this frame, this is our starting point!
                */
                if (allObjectsHaveData) {
                  return frameNumber;
                }
              }

              /*
                If we get here, it means we couldn't find a frame where all objects
                have data. This shouldn't happen in a properly functioning system.
              */
              throw 'corrupted object annotations';
            }

            /*
              TRACK FUNCTION - THE CORE TRACKING LOGIC
              
              This function handles the tracking for a single frame. It determines what
              needs to be computed versus what can be retrieved from existing data,
              and coordinates the optical flow calculations when needed.
              
              Think of it like a director preparing for one specific scene:
              1. Check which actors already know their positions
              2. For actors who don't know their positions, calculate where they should be
              3. Combine all the position information and return the complete scene
            */
            track(frameNumber) {
              return new Promise((resolve, _) => {
                /*
                  Get the actual image data for this frame. We need the image to:
                  1. Display it to the user
                  2. Run optical flow calculations (if needed)
                */
                this.framesManager.frames.getFrame(frameNumber).then((blob) => {
                  blobToImage(blob).then((img) => {
                    /*
                      Separate objects into two categories:
                      1. Objects that already have position data for this frame
                      2. Objects that need their positions calculated using optical flow
                    */
                    let result = [];    // Objects with known positions
                    let toCompute = []; // Objects that need position calculations
                    
                    for (let i = 0; i < this.annotatedObjects.length; i++) {
                      let annotatedObject = this.annotatedObjects[i];
                      let annotatedFrame = annotatedObject.get(frameNumber);
                      
                      if (annotatedFrame == null) {
                        /*
                          This object doesn't have data for the current frame.
                          Get its position from the previous frame so we can track it forward.
                        */
                        annotatedFrame = annotatedObject.get(frameNumber - 1);
                        if (annotatedFrame == null) {
                          /*
                            This shouldn't happen if startFrame() worked correctly.
                            We should always have data for the previous frame.
                          */
                          throw 'tracking must be done sequentially';
                        }
                        toCompute.push({annotatedObject: annotatedObject, bbox: annotatedFrame.bbox});
                      } else {
                        /*
                          This object already has position data for this frame
                          (probably from a human annotation or previous calculation).
                        */
                        result.push({annotatedObject: annotatedObject, annotatedFrame: annotatedFrame});
                      }
                    }

                    /*
                      Extract just the bounding boxes from objects that need computation.
                      This creates an array like [bbox1, bbox2, bbox3] that we can
                      pass to the optical flow algorithm.
                    */
                    let bboxes = toCompute.map(c => c.bbox);
                    let hasAnyBbox = bboxes.some(bbox => bbox != null); // Do we have any visible objects to track?
                    
                    /*
                      Prepare the optical flow system if we have objects to track.
                      If all objects are invisible (bbox = null), we can skip optical flow.
                    */
                    let optionalOpticalFlowInit;
                    if (hasAnyBbox) {
                      optionalOpticalFlowInit = this.initOpticalFlow(frameNumber - 1);
                    } else {
                      optionalOpticalFlowInit = new Promise((r, _) => { r(); }); // Do nothing
                    }

                    /*
                      Wait for optical flow initialization to complete, then run the tracking
                    */
                    optionalOpticalFlowInit.then(() => {
                      let newBboxes; // Array to store the updated bounding box positions
                      
                      if (hasAnyBbox) {
                        /*
                          We have visible objects to track. Run optical flow to calculate
                          their new positions.
                        */
                        let imageData = this.imageData(img); // Convert image to format needed by optical flow
                        newBboxes = this.opticalFlow.track(imageData, bboxes); // Run the tracking algorithm
                        this.lastFrame = frameNumber; // Remember which frame we just processed
                      } else {
                        /*
                          No visible objects to track. Just use the existing bboxes
                          (which should all be null, meaning invisible).
                        */
                        newBboxes = bboxes;
                      }

                      /*
                        Create new AnnotatedFrame objects for all the computed positions
                        and add them to the appropriate AnnotatedObject collections.
                      */
                      for (let i = 0; i < toCompute.length; i++) {
                        let annotatedObject = toCompute[i].annotatedObject;
                        /*
                          Create a new AnnotatedFrame with:
                          - frameNumber: the current frame
                          - newBboxes[i]: the calculated position (or null if not visible)
                          - false: this is not ground truth (it's a computer calculation)
                        */
                        let annotatedFrame = new AnnotatedFrame(frameNumber, newBboxes[i], false);
                        annotatedObject.add(annotatedFrame); // Add this frame to the object's history
                        result.push({annotatedObject: annotatedObject, annotatedFrame: annotatedFrame});
                      }

                      /*
                        Return the complete result: the image plus all object positions
                        This gives the caller everything they need to display the frame
                        with all objects properly positioned.
                      */
                      resolve({img: img, objects: result});
                    });
                  });
                });
              });
            }

            /*
              OPTICAL FLOW INITIALIZATION - PREPARING THE MOTION DETECTOR
              
              This function prepares the optical flow system to track motion from a specific frame.
              The optical flow algorithm needs to compare two consecutive frames, so it needs
              to be "primed" with the previous frame before it can calculate motion to the current frame.
              
              Think of it like loading a "before" photo into a motion detector so it can compare
              it with an "after" photo and calculate how things moved.
            */
            initOpticalFlow(frameNumber) {
              return new Promise((resolve, _) => {
                /*
                  Optimization: If we just processed this exact frame, we don't need to
                  reload it. The optical flow system already has this frame in memory.
                */
                if (this.lastFrame != -1 && this.lastFrame == frameNumber) {
                  resolve(); // Already initialized for this frame
                } else {
                  /*
                    We need to load a new frame for optical flow initialization.
                    Reset the optical flow system and load the specified frame.
                  */
                  this.opticalFlow.reset(); // Clear any previous data
                  
                  /*
                    Load the frame image and initialize the optical flow system with it
                  */
                  this.framesManager.frames.getFrame(frameNumber).then((blob) => {
                    blobToImage(blob).then((img) => {
                      let imageData = this.imageData(img); // Convert to the format optical flow needs
                      this.opticalFlow.init(imageData);    // Initialize optical flow with this image
                      this.lastFrame = frameNumber;        // Remember which frame we loaded
                      resolve(); // Initialization complete
                    });
                  });
                }
              });
            }

            /*
              IMAGE DATA CONVERTER - PREPARING IMAGES FOR COMPUTER VISION
              
              This function converts an Image object (which is good for displaying to users)
              into ImageData (which is good for computer vision algorithms). 
              
              Think of it like converting a photo from "display format" (nice to look at)
              to "analysis format" (easy for computers to process pixel by pixel).
              
              The computer vision algorithms need access to the raw pixel data - the exact
              red, green, and blue values for every single pixel in the image.
            */
            imageData(img) {
              /*
                Set up a canvas that matches the image size. The canvas is like a
                temporary workspace where we can draw the image and then extract
                the pixel data.
              */
              let canvas = this.ctx.canvas;
              canvas.width = img.width;   // Make canvas the same width as the image
              canvas.height = img.height; // Make canvas the same height as the image
              
              /*
                Draw the image onto the canvas. This is like printing a photo
                onto a special paper that lets us read the color values.
              */
              this.ctx.drawImage(img, 0, 0);
              
              /*
                Extract the pixel data from the canvas. This gives us an array
                containing the red, green, blue, and transparency values for
                every single pixel in the image.
                
                The result is an ImageData object that computer vision algorithms
                can work with directly.
              */
              return this.ctx.getImageData(0, 0, canvas.width, canvas.height);
            }
          };

      


     </script>
    
    <!-- 
      ANNOTATION CLASS MANAGEMENT SYSTEM
      This handles the creation and management of annotation classes with unique colors.
      Think of it like having a palette of different colored markers for different types of annotations.
    -->
    <!-- annotation class management -->
    <!-- <script type="text/javascript" src="dist/class-manager.js"></script> -->

    <script type="text/javascript">
      /**
 * ANNOTATION CLASS MANAGEMENT SYSTEM
 * 
 * This module handles the creation, storage, and management of annotation classes
 * with unique colors. It allows users to dynamically create classes during runtime
 * and ensures the class information is included in all exports.
 */

// Global object to store annotation classes and their colors
let annotationClasses = {};

// Initialize with some default classes
const defaultClasses = {
    'cracks': '#FF0000',        // Red
    'spalling': '#00FF00',      // Green
    'corrosion': '#0000FF',     // Blue
    'general': '#FFFF00'        // Yellow
};

/**
 * Initialize the class management system
 */
function initializeClassManager() {
    // Load default classes
    Object.assign(annotationClasses, defaultClasses);
    
    // Set up event listeners
    setupClassManagerEventListeners();
    
    // Update UI with default classes
    updateClassDisplay();
    updateClassDropdown();
    
    // Set initial random color
    const colorInput = document.getElementById('newClassColor');
    if (colorInput) {
        colorInput.value = generateRandomColor();
    }
    
    console.log('Class manager initialized with default classes:', annotationClasses);
}

/**
 * Set up event listeners for class management UI elements
 */
function setupClassManagerEventListeners() {
    // Add class button
    const addClassButton = document.getElementById('addClassButton');
    if (addClassButton) {
        addClassButton.addEventListener('click', addNewClass);
    }
    
    // Class name input (Enter key support)
    const classNameInput = document.getElementById('newClassName');
    if (classNameInput) {
        classNameInput.addEventListener('keypress', function(e) {
            if (e.key === 'Enter') {
                addNewClass();
            }
        });
    }
    
    // Class selection dropdown
    const classDropdown = document.getElementById('annotationClass');
    if (classDropdown) {
        classDropdown.addEventListener('change', updateClassPreview);
    }
    
    // Color input
    const colorInput = document.getElementById('newClassColor');
    if (colorInput) {
        colorInput.addEventListener('change', function() {
            // Generate a random color if user wants variety
            // This is just visual feedback
        });
    }
}

/**
 * Add a new annotation class
 */
function addNewClass() {
    const classNameInput = document.getElementById('newClassName');
    const classColorInput = document.getElementById('newClassColor');
    
    if (!classNameInput || !classColorInput) {
        console.error('Class creation elements not found');
        return;
    }
    
    const className = classNameInput.value.trim().toLowerCase();
    const classColor = classColorInput.value;
    
    // Validation
    if (!className) {
        alert('Please enter a class name');
        classNameInput.focus();
        return;
    }
    
    if (annotationClasses.hasOwnProperty(className)) {
        alert(`Class "${className}" already exists. Please choose a different name.`);
        classNameInput.focus();
        return;
    }
    
    // Add the new class
    annotationClasses[className] = classColor;
    
    // Update UI
    updateClassDisplay();
    updateClassDropdown();
    
    // Notify annotation manager to refresh class dropdowns
    if (window.annotationManager && typeof window.annotationManager.refreshClassDropdowns === 'function') {
        window.annotationManager.refreshClassDropdowns();
    }
    
    // Clear inputs
    classNameInput.value = '';
    classColorInput.value = generateRandomColor();
    
    // Auto-select the newly created class
    const classDropdown = document.getElementById('annotationClass');
    if (classDropdown) {
        classDropdown.value = className;
        updateClassPreview();
    }
    
    console.log(`Added new class: ${className} with color ${classColor}`);
    alert(`Class "${className}" added successfully!`);
}

/**
 * Update the display of available classes
 */
function updateClassDisplay() {
    const classList = document.getElementById('classList');
    if (!classList) return;
    
    classList.innerHTML = '';
    
    Object.entries(annotationClasses).forEach(([className, color]) => {
        const listItem = document.createElement('li');
        listItem.style.marginBottom = '5px';
        listItem.style.padding = '5px';
        listItem.style.border = '1px solid #ddd';
        listItem.style.borderRadius = '3px';
        listItem.style.backgroundColor = '#fff';
        
        listItem.innerHTML = `
            <span style="display: inline-block; width: 20px; height: 20px; background-color: ${color}; border: 1px solid #000; margin-right: 10px; vertical-align: middle;"></span>
            <strong>${className}</strong> (${color})
            <button onclick="removeClass('${className}')" style="float: right; background: #ff4444; color: white; border: none; padding: 2px 6px; border-radius: 3px; cursor: pointer;">Remove</button>
        `;
        
        classList.appendChild(listItem);
    });
}

/**
 * Update the class selection dropdown
 */
function updateClassDropdown() {
    const classDropdown = document.getElementById('annotationClass');
    if (!classDropdown) return;
    
    const currentValue = classDropdown.value;
    classDropdown.innerHTML = '<option value="">Select a class</option>';
    
    Object.keys(annotationClasses).forEach(className => {
        const option = document.createElement('option');
        option.value = className;
        option.textContent = className.charAt(0).toUpperCase() + className.slice(1);
        classDropdown.appendChild(option);
    });
    
    // Restore previous selection if it still exists
    if (currentValue && annotationClasses.hasOwnProperty(currentValue)) {
        classDropdown.value = currentValue;
    }
    
    updateClassPreview();
}

/**
 * Update the color preview for the selected class
 */
function updateClassPreview() {
    const classDropdown = document.getElementById('annotationClass');
    const preview = document.getElementById('selectedClassPreview');
    
    if (!classDropdown || !preview) return;
    
    const selectedClass = classDropdown.value;
    if (selectedClass && annotationClasses[selectedClass]) {
        preview.style.backgroundColor = annotationClasses[selectedClass];
        preview.style.display = 'inline-block';
        preview.title = `${selectedClass} (${annotationClasses[selectedClass]})`;
    } else {
        preview.style.display = 'none';
    }
}

/**
 * Remove a class (with confirmation)
 */
function removeClass(className) {
    if (!annotationClasses.hasOwnProperty(className)) {
        return;
    }
    
    // Check if this class is being used by any annotations
    // Note: This would need to be integrated with the main annotation system
    const confirmMessage = `Are you sure you want to remove the class "${className}"?\n\nThis action cannot be undone.`;
    
    if (confirm(confirmMessage)) {
        delete annotationClasses[className];
        updateClassDisplay();
        updateClassDropdown();
        console.log(`Removed class: ${className}`);
    }
}

/**
 * Get the currently selected annotation class
 */
function getCurrentAnnotationClass() {
    const classDropdown = document.getElementById('annotationClass');
    if (!classDropdown) return null;
    
    const selectedClass = classDropdown.value;
    if (!selectedClass) {
        alert('Please select an annotation class before creating annotations');
        return null;
    }
    
    return selectedClass;
}

/**
 * Get the color for a specific class
 */
function getClassColor(className) {
    return annotationClasses[className] || '#000000';
}

/**
 * Get all available classes
 */
function getAllClasses() {
    return { ...annotationClasses };
}

/**
 * Generate a random color for new classes
 */
function generateRandomColor() {
    const colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8', '#F7DC6F', '#BB8FCE', '#85C1E9', '#F8C471', '#82E0AA'];
    return colors[Math.floor(Math.random() * colors.length)];
}

/**
 * Export classes information for XML
 */
function exportClassesForXML() {
    let classesXML = '  <classes>\n';
    Object.entries(annotationClasses).forEach(([className, color]) => {
        classesXML += `    <class name="${className}" color="${color}" />\n`;
    });
    classesXML += '  </classes>\n';
    return classesXML;
}

/**
 * Import classes from XML
 */
function importClassesFromXML(xmlDoc) {
    try {
        const classElements = xmlDoc.getElementsByTagName('class');
        let importedCount = 0;
        
        for (let i = 0; i < classElements.length; i++) {
            const classElement = classElements[i];
            const className = classElement.getAttribute('name');
            const classColor = classElement.getAttribute('color');
            
            if (className && classColor) {
                annotationClasses[className] = classColor;
                importedCount++;
            }
        }
        
        if (importedCount > 0) {
            updateClassDisplay();
            updateClassDropdown();
            console.log(`Imported ${importedCount} classes from XML`);
        }
    } catch (error) {
        console.error('Error importing classes from XML:', error);
    }
}

/**
 * Reset classes to defaults
 */
function resetToDefaultClasses() {
    if (confirm('Are you sure you want to reset all classes to defaults? This will remove any custom classes you\'ve created.')) {
        annotationClasses = { ...defaultClasses };
        updateClassDisplay();
        updateClassDropdown();
        
        // Notify annotation manager to refresh class dropdowns
        if (window.annotationManager && typeof window.annotationManager.refreshClassDropdowns === 'function') {
            window.annotationManager.refreshClassDropdowns();
        }
        
        console.log('Classes reset to defaults');
    }
}

// Initialize when the page loads
document.addEventListener('DOMContentLoaded', function() {
    // Wait a bit to ensure other scripts are loaded
    setTimeout(initializeClassManager, 100);
});

// Make key functions and variables globally accessible
window.annotationClasses = annotationClasses;
window.getCurrentAnnotationClass = getCurrentAnnotationClass;
window.getClassColor = getClassColor;
window.getAllClasses = getAllClasses;
window.resetToDefaultClasses = resetToDefaultClasses;

// Make functions available globally for onclick handlers
window.removeClass = removeClass;
window.resetToDefaultClasses = resetToDefaultClasses;

    </script>
    
    <!-- 
      INDIVIDUAL ANNOTATION MANAGEMENT SYSTEM
      This handles the creation and management of individual annotation cards with detailed controls.
      Think of it like having a detailed inventory system for each annotation you create.
    -->
    <!-- individual annotation management -->
    <!-- <script type="text/javascript" src="dist/annotation-manager.js"></script> -->
     <script type ="text/javascript"> /*
  ANNOTATION-MANAGER.JS - INDIVIDUAL ANNOTATION UI MANAGEMENT
  
  This file manages the individual annotation cards that show detailed information
  for each annotation created by the user. Think of it like a detailed inventory
  system where each annotation gets its own information card.
  
  Features:
  - Creates dynamic annotation cards with class-colored borders
  - Manages visibility controls (is visible, hidden checkboxes)
  - Handles annotation comments and metadata
  - Provides bulk actions for multiple annotations
  - Integrates with the existing annotation system
*/

"use strict";

/*
  ANNOTATION MANAGER CLASS
  This class handles all the UI operations for individual annotations
*/
class AnnotationManager {
  constructor() {
    this.annotations = new Map(); // Map to store annotation data by ID
    this.annotationIdCounter = 1; // Counter for generating unique annotation IDs
    this.currentFrameNumber = 0; // Track current video frame
    
    // Get references to DOM elements
    this.annotationsList = document.getElementById('annotationsList');
    this.noAnnotationsMessage = document.getElementById('noAnnotationsMessage');
    
    // Initialize the manager
    this.initialize();
  }
  
  /*
    INITIALIZATION
    Set up event listeners and initial state
  */
  initialize() {
    // Hide the "no annotations" message initially
    this.updateNoAnnotationsMessage();
    
    // Set up periodic updates to sync visibility with video playback
    setInterval(() => {
      this.updateAnnotationVisibilityStates();
    }, 100); // Check every 100ms
  }
  
  /*
    CREATE ANNOTATION CARD
    Creates a new annotation card when an annotation is added
  */
  createAnnotationCard(annotatedObject, classInfo) {
    const annotationId = this.annotationIdCounter++;
    const classColor = classInfo ? classInfo.color : '#FF0000';
    const className = classInfo ? classInfo.name : 'Unknown';
    
    // Store annotation data
    const annotationData = {
      id: annotationId,
      annotatedObject: annotatedObject,
      classInfo: classInfo,
      comments: '',
      isVisible: true,
      isHidden: false,
      createdFrame: this.currentFrameNumber
    };
    
    this.annotations.set(annotationId, annotationData);
    
    // Create the HTML for the annotation card
    const cardHtml = this.generateAnnotationCardHtml(annotationData);
    
    // Add the card to the container
    const cardElement = document.createElement('div');
    cardElement.innerHTML = cardHtml;
    cardElement.classList.add('annotation-card');
    cardElement.style.borderColor = classColor;
    cardElement.setAttribute('data-annotation-id', annotationId);
    
    this.annotationsList.appendChild(cardElement);
    
    // Set up event listeners for this card
    this.setupCardEventListeners(cardElement, annotationData);
    
    // Update the no annotations message
    this.updateNoAnnotationsMessage();
    
    return annotationId;
  }
  
  /*
    GENERATE ANNOTATION CARD HTML
    Creates the HTML structure for an annotation card
  */
  generateAnnotationCardHtml(annotationData) {
    const { id, classInfo, comments, isVisible, isHidden } = annotationData;
    const classColor = classInfo ? classInfo.color : '#FF0000';
    const className = classInfo ? classInfo.name : 'Unknown';
    
    return `
      <div class="annotation-header">
        <div class="annotation-id">ID: ${id}</div>
        <div class="annotation-class">
          <span class="class-color-indicator" style="background-color: ${classColor};"></span>
          <span>${className}</span>
        </div>
      </div>
      
      <div class="annotation-details">
        <div class="annotation-field">
          <label>Class:</label>
          <select class="class-selector" data-annotation-id="${id}">
            ${this.generateClassOptions(classInfo)}
          </select>
        </div>
        
        <div class="annotation-field">
          <label>Type:</label>
          <input type="text" class="annotation-type" placeholder="e.g., Vehicle, Person" value="${annotationData.type || ''}" data-annotation-id="${id}">
        </div>
        
        <div class="annotation-field" style="grid-column: 1 / -1;">
          <label>Comments:</label>
          <textarea class="annotation-comments" placeholder="Add notes about this annotation..." data-annotation-id="${id}">${comments}</textarea>
        </div>
      </div>
      
      <div class="annotation-controls">
        <div class="visibility-controls">
          <label>
            <input type="checkbox" class="is-visible-checkbox" ${isVisible ? 'checked' : ''} data-annotation-id="${id}">
            Is Visible
          </label>
          <label>
            <input type="checkbox" class="is-hidden-checkbox" ${isHidden ? 'checked' : ''} data-annotation-id="${id}">
            Hidden
          </label>
        </div>
        
        <div class="annotation-actions">
          <button class="edit-btn" data-annotation-id="${id}">Edit</button>
          <button class="focus-btn" data-annotation-id="${id}">Focus</button>
          <button class="delete-btn" data-annotation-id="${id}">Delete</button>
        </div>
      </div>
    `;
  }
  
  /*
    GENERATE CLASS OPTIONS
    Creates option elements for the class selector dropdown
  */
  generateClassOptions(selectedClass) {
    let options = '<option value="">Select a class</option>';
    
    // Get available classes from the global annotation classes
    if (typeof window.annotationClasses !== 'undefined') {
      Object.keys(window.annotationClasses).forEach(className => {
        const classColor = window.annotationClasses[className];
        const selected = selectedClass && selectedClass.name === className ? 'selected' : '';
        options += `<option value="${className}" data-color="${classColor}" ${selected}>${className}</option>`;
      });
    }
    
    return options;
  }
  
  /*
    SETUP CARD EVENT LISTENERS
    Adds event listeners to all interactive elements in an annotation card
  */
  setupCardEventListeners(cardElement, annotationData) {
    const annotationId = annotationData.id;
    
    // Class selector change
    const classSelector = cardElement.querySelector('.class-selector');
    classSelector.addEventListener('change', (e) => {
      this.handleClassChange(annotationId, e.target);
    });
    
    // Type field change
    const typeField = cardElement.querySelector('.annotation-type');
    typeField.addEventListener('change', (e) => {
      annotationData.type = e.target.value;
    });
    
    // Comments change
    const commentsField = cardElement.querySelector('.annotation-comments');
    commentsField.addEventListener('change', (e) => {
      annotationData.comments = e.target.value;
    });
    
    // Visibility checkboxes
    const visibleCheckbox = cardElement.querySelector('.is-visible-checkbox');
    visibleCheckbox.addEventListener('change', (e) => {
      this.handleVisibilityChange(annotationId, e.target.checked, 'visible');
    });
    
    const hiddenCheckbox = cardElement.querySelector('.is-hidden-checkbox');
    hiddenCheckbox.addEventListener('change', (e) => {
      this.handleVisibilityChange(annotationId, e.target.checked, 'hidden');
    });
    
    // Action buttons
    const editBtn = cardElement.querySelector('.edit-btn');
    editBtn.addEventListener('click', () => {
      this.handleEditAnnotation(annotationId);
    });
    
    const focusBtn = cardElement.querySelector('.focus-btn');
    focusBtn.addEventListener('click', () => {
      this.handleFocusAnnotation(annotationId);
    });
    
    const deleteBtn = cardElement.querySelector('.delete-btn');
    deleteBtn.addEventListener('click', () => {
      this.handleDeleteAnnotation(annotationId);
    });
  }
  
  /*
    HANDLE CLASS CHANGE
    Updates annotation when class is changed
  */
  handleClassChange(annotationId, selectElement) {
    const annotationData = this.annotations.get(annotationId);
    const selectedOption = selectElement.selectedOptions[0];
    
    if (selectedOption && selectedOption.value) {
      const newClassInfo = {
        name: selectedOption.value,
        color: selectedOption.getAttribute('data-color')
      };
      
      annotationData.classInfo = newClassInfo;
      
      // Update the actual annotation object's class and color
      if (annotationData.annotatedObject) {
        annotationData.annotatedObject.className = newClassInfo.name;
        annotationData.annotatedObject.color = newClassInfo.color;
        
        // Update the visual bounding box color in the video
        if (annotationData.annotatedObject.dom) {
          annotationData.annotatedObject.dom.style.borderColor = newClassInfo.color;
        }
      }
      
      // Update the card's border color
      const cardElement = document.querySelector(`[data-annotation-id="${annotationId}"]`);
      cardElement.style.borderColor = newClassInfo.color;
      
      // Update the class color indicator
      const colorIndicator = cardElement.querySelector('.class-color-indicator');
      colorIndicator.style.backgroundColor = newClassInfo.color;
      
      // Update the class name display
      const classNameSpan = cardElement.querySelector('.annotation-class span:last-child');
      classNameSpan.textContent = newClassInfo.name;
    }
  }
  
  /*
    HANDLE VISIBILITY CHANGE
    Manages the visibility checkboxes and their effects
  */
  handleVisibilityChange(annotationId, checked, type) {
    const annotationData = this.annotations.get(annotationId);
    const cardElement = document.querySelector(`[data-annotation-id="${annotationId}"]`);
    
    if (type === 'visible') {
      annotationData.isVisible = checked;
      
      // Update the actual annotation visibility in the video
      if (annotationData.annotatedObject && annotationData.annotatedObject.dom) {
        annotationData.annotatedObject.dom.style.display = checked ? 'block' : 'none';
      }
      
    } else if (type === 'hidden') {
      annotationData.isHidden = checked;
      
      // Apply visual effects to the card
      if (checked) {
        cardElement.classList.add('hidden');
      } else {
        cardElement.classList.remove('hidden');
      }
      
      // Hide/show the actual annotation in the video
      if (annotationData.annotatedObject && annotationData.annotatedObject.dom) {
        annotationData.annotatedObject.dom.style.display = checked ? 'none' : 'block';
      }
    }
  }
  
  /*
    HANDLE EDIT ANNOTATION
    Allows editing of annotation properties
  */
  handleEditAnnotation(annotationId) {
    const annotationData = this.annotations.get(annotationId);
    // TODO: Implement edit functionality (could open a modal or enable inline editing)
    console.log('Editing annotation:', annotationData);
  }
  
  /*
    HANDLE FOCUS ANNOTATION
    Focuses the video on the frame where this annotation appears
  */
  handleFocusAnnotation(annotationId) {
    const annotationData = this.annotations.get(annotationId);
    // TODO: Jump to the frame where this annotation was created and highlight it
    console.log('Focusing on annotation:', annotationData);
    
    // If there's a slider control, jump to the annotation's frame
    if (typeof slider !== 'undefined' && slider.slider) {
      slider.slider('value', annotationData.createdFrame);
    }
  }
  
  /*
    HANDLE DELETE ANNOTATION
    Removes an annotation and its card
  */
  handleDeleteAnnotation(annotationId) {
    if (confirm('Are you sure you want to delete this annotation?')) {
      const annotationData = this.annotations.get(annotationId);
      console.log('Deleting annotation:', annotationId, annotationData);
      
      // Remove the actual annotation from the video system
      if (annotationData.annotatedObject && typeof window.annotatedObjectsTracker !== 'undefined') {
        // Find the index of this annotation in the tracker
        const index = window.annotatedObjectsTracker.annotatedObjects.findIndex(
          obj => obj === annotationData.annotatedObject
        );
        
        console.log('Found annotation at index:', index);
        console.log('Total annotations before deletion:', window.annotatedObjectsTracker.annotatedObjects.length);
        
        if (index !== -1) {
          // Use the existing clearAnnotatedObject function to properly remove it
          if (typeof window.clearAnnotatedObject === 'function') {
            console.log('Using clearAnnotatedObject function');
            window.clearAnnotatedObject(index);
            console.log('Total annotations after deletion:', window.annotatedObjectsTracker.annotatedObjects.length);
          } else {
            console.log('clearAnnotatedObject not available, using manual cleanup');
            // Manual cleanup fallback
            const annotatedObject = annotationData.annotatedObject;
            
            try {
              // Remove UI controls if they exist
              if (annotatedObject.controls) {
                console.log('Removing controls:', annotatedObject.controls);
                if (typeof annotatedObject.controls.remove === 'function') {
                  annotatedObject.controls.remove();
                } else if (annotatedObject.controls.parentNode) {
                  annotatedObject.controls.parentNode.removeChild(annotatedObject.controls);
                }
              }
              
              // Remove visual bounding box
              if (annotatedObject.dom) {
                console.log('Removing DOM element:', annotatedObject.dom);
                if (typeof $ !== 'undefined') {
                  $(annotatedObject.dom).remove();
                } else if (annotatedObject.dom.parentNode) {
                  annotatedObject.dom.parentNode.removeChild(annotatedObject.dom);
                }
              }
              
              // Remove from tracker array
              console.log('Removing from tracker array at index:', index);
              window.annotatedObjectsTracker.annotatedObjects.splice(index, 1);
              console.log('Total annotations after manual deletion:', window.annotatedObjectsTracker.annotatedObjects.length);
              
            } catch (error) {
              console.error('Error during manual annotation deletion:', error);
            }
          }
        } else {
          console.warn('Could not find annotation in tracker array');
        }
      }
      
      // Remove from our local storage
      this.annotations.delete(annotationId);
      console.log('Remaining annotations in manager:', this.annotations.size);
      
      // Remove the card from DOM
      const cardElement = document.querySelector(`[data-annotation-id="${annotationId}"]`);
      if (cardElement) {
        cardElement.remove();
        console.log('Removed annotation card from DOM');
      }
      
      // Update the no annotations message
      this.updateNoAnnotationsMessage();
      
      console.log('Annotation deletion complete');
    }
  }
  
  /*
    UPDATE NO ANNOTATIONS MESSAGE
    Shows/hides the "no annotations" message based on current annotations
  */
  updateNoAnnotationsMessage() {
    if (this.annotations.size === 0) {
      this.noAnnotationsMessage.style.display = 'block';
    } else {
      this.noAnnotationsMessage.style.display = 'none';
    }
  }
  
  /*
    UPDATE ANNOTATION VISIBILITY STATES
    Periodically checks and updates the visibility states based on current frame
  */
  updateAnnotationVisibilityStates() {
    // TODO: Implement logic to check which annotations should be visible in the current frame
    // This would integrate with the existing annotation tracking system
  }
  
  /*
    SET CURRENT FRAME
    Updates the current frame number for tracking purposes
  */
  setCurrentFrame(frameNumber) {
    this.currentFrameNumber = frameNumber;
  }
  
  /*
    REFRESH CLASS DROPDOWNS
    Updates all class dropdowns when new classes are added
  */
  refreshClassDropdowns() {
    // Update all class selector dropdowns in existing annotation cards
    const classSelectors = document.querySelectorAll('.class-selector');
    classSelectors.forEach(selector => {
      const currentValue = selector.value;
      selector.innerHTML = this.generateClassOptions({ name: currentValue });
      selector.value = currentValue; // Restore the selected value
    });
  }
  
  /*
    REFRESH OBJECTS DISPLAY
    Forces a refresh of the objects panel to show current annotations
  */
  refreshObjectsDisplay() {
    // Clear the objects panel
    const objectsPanel = document.getElementById('objects');
    if (objectsPanel) {
      objectsPanel.innerHTML = '';
    }
    
    // Recreate the control panels for all remaining annotations
    if (window.annotatedObjectsTracker && window.annotatedObjectsTracker.annotatedObjects) {
      window.annotatedObjectsTracker.annotatedObjects.forEach((annotatedObject) => {
        if (typeof window.addAnnotatedObjectControls === 'function') {
          window.addAnnotatedObjectControls(annotatedObject);
        }
      });
    }
  }
}

/*
  BULK ACTIONS
  Global functions for managing multiple annotations at once
*/

function toggleAllAnnotationsVisibility(visible) {
  console.log('Toggling all annotations visibility to:', visible);
  
  if (window.annotationManager) {
    // Update our annotation manager's annotations
    window.annotationManager.annotations.forEach((annotationData, id) => {
      annotationData.isVisible = visible;
      
      // Update the actual annotation visibility in the video
      if (annotationData.annotatedObject && annotationData.annotatedObject.dom) {
        annotationData.annotatedObject.dom.style.display = visible ? 'block' : 'none';
      }
      
      // Update the checkbox
      const checkbox = document.querySelector(`[data-annotation-id="${id}"] .is-visible-checkbox`);
      if (checkbox) {
        checkbox.checked = visible;
      }
    });
    
    // Also update any annotations that might exist in the global tracker but not in our manager
    if (window.annotatedObjectsTracker && window.annotatedObjectsTracker.annotatedObjects) {
      window.annotatedObjectsTracker.annotatedObjects.forEach(annotatedObject => {
        if (annotatedObject.dom) {
          annotatedObject.dom.style.display = visible ? 'block' : 'none';
        }
      });
    }
  }
}

function deleteAllAnnotations() {
  if (confirm('Are you sure you want to delete ALL annotations? This cannot be undone.')) {
    console.log('Starting delete all annotations...');
    
    if (window.annotationManager) {
      // First, use the global clearAllAnnotatedObjects function if available
      if (typeof window.clearAllAnnotatedObjects === 'function') {
        console.log('Using clearAllAnnotatedObjects function');
        window.clearAllAnnotatedObjects();
      } else {
        // Fallback: manually clear each annotation
        console.log('Manual cleanup of all annotations');
        
        if (window.annotatedObjectsTracker && window.annotatedObjectsTracker.annotatedObjects) {
          // Create a copy of the array since we'll be modifying it
          const annotationsToDelete = [...window.annotatedObjectsTracker.annotatedObjects];
          
          annotationsToDelete.forEach((annotatedObject, index) => {
            try {
              // Remove UI controls if they exist
              if (annotatedObject.controls) {
                console.log('Removing controls for annotation', index);
                if (typeof annotatedObject.controls.remove === 'function') {
                  annotatedObject.controls.remove();
                } else if (annotatedObject.controls.parentNode) {
                  annotatedObject.controls.parentNode.removeChild(annotatedObject.controls);
                }
              }
              
              // Remove visual bounding box
              if (annotatedObject.dom) {
                console.log('Removing DOM element for annotation', index);
                if (typeof $ !== 'undefined') {
                  $(annotatedObject.dom).remove();
                } else if (annotatedObject.dom.parentNode) {
                  annotatedObject.dom.parentNode.removeChild(annotatedObject.dom);
                }
              }
            } catch (error) {
              console.error('Error removing annotation', index, error);
            }
          });
          
          // Clear the entire array
          window.annotatedObjectsTracker.annotatedObjects.length = 0;
        }
      }
      
      // Clear the objects panel manually
      const objectsPanel = document.getElementById('objects');
      if (objectsPanel) {
        console.log('Clearing objects panel');
        objectsPanel.innerHTML = '';
      }
      
      // Clear all annotations from our manager
      console.log('Clearing annotation manager storage');
      window.annotationManager.annotations.clear();
      
      // Remove all annotation cards
      const cards = document.querySelectorAll('.annotation-card');
      console.log('Removing', cards.length, 'annotation cards');
      cards.forEach(card => card.remove());
      
      // Update message
      window.annotationManager.updateNoAnnotationsMessage();
      
      console.log('Delete all annotations complete');
    }
  }
}

// Initialize the annotation manager when the page loads
document.addEventListener('DOMContentLoaded', function() {
  window.annotationManager = new AnnotationManager();
  
  // Hook into existing annotation creation (this would need to be integrated with annotate.js)
  // This is a placeholder - actual integration would depend on how annotations are currently created
  window.createAnnotationCard = function(annotatedObject, classInfo) {
    return window.annotationManager.createAnnotationCard(annotatedObject, classInfo);
  };
});
</script>
    
    <!-- 
      ANNOTATION MANAGEMENT SYSTEM
      This handles all the logic for creating, editing, and tracking the bounding boxes.
      Think of it like the conductor of an orchestra - it coordinates all the annotation activities.
    -->
    <!-- annotation handling annotate.js -->
    <!-- <script type="text/javascript" src="dist/annotate.js"></script> -->
     <script type="text/javascript">
      /*
  ANNOTATE.JS - THE VIDEO ANNOTATION USER INTERFACE
  
  This file is like the control panel of our video annotation tool. Think of it like the
  dashboard of a car - it has all the buttons, dials, and displays that let you control
  the engine (framez.js) and see what's happening.
  
  What this file does:
  1. Sets up all the user interface controls (play/pause buttons, sliders, etc.)
  2. Handles user interactions (clicking, dragging, typing)
  3. Coordinates between the user interface and the video processing engine
  4. Manages the annotation workflow (drawing boxes, tracking objects, exporting results)
  
  Think of it like being the director of a movie production:
  - The framez.js is like the camera crew (handles the technical video work)
  - This file is like the director (coordinates everything and responds to what happens)
  - The HTML is like the movie set (provides the physical space where everything happens)
*/

"use strict"; // Tell JavaScript to be extra careful about catching programming mistakes

      /*
        CONFIGURATION OBJECT - THE SETTINGS CONTROL PANEL
        
        This object is like the settings menu in a video game or app. It contains all the
        important numbers and preferences that control how the video annotation tool works.
        
        Think of it like the control settings on a camera:
        - ISO setting controls light sensitivity
        - Shutter speed controls motion blur
        - These settings control video processing and quality
        
        Why have a config object?
        Instead of scattering magic numbers throughout the code, we put them all in one
        place. This makes it easy to adjust settings without hunting through hundreds of
        lines of code. It's like having all your TV remote's settings in one menu.
      */
      let config = {
        // Should be higher than real FPS to not skip real frames
        // Hardcoded due to JS limitations
        fps: 30, // Frames per second - how many pictures per second we expect from the video
        
        // Low rate decreases the chance of losing frames with poor browser performances
        playbackRate: 0.4, // Play video at 40% normal speed during frame extraction (slower = more reliable)

        // Format of the extracted frames
        imageMimeType: 'image/jpeg', // Save frames as JPEG files (good compression, smaller files)
        imageExtension: '.jpg',      // File extension for saved frames

        // Name of the extracted frames zip archive
        framesZipFilename: 'extracted-frames.zip' // Default name for the downloaded ZIP file
      };

      /*
        DOM ELEMENT REFERENCES - CONNECTING TO THE USER INTERFACE
        
        These variables are like getting handles on all the controls in your car dashboard.
        Before you can use the steering wheel, you need to grab it. Before you can use
        the radio, you need to know where the volume knob is.
        
        document.querySelector() is like saying "find me the element with this ID"
        It's like looking for a specific button on a control panel by reading its label.
        
        Think of it like this: The HTML created all these buttons and input fields,
        but they're just sitting there. These lines create "remote controls" that let
        our JavaScript code actually operate those buttons and fields.
        
        Why store these in variables?
        1. Performance: Looking up elements is slow, so we do it once and remember the result
        2. Convenience: Instead of typing document.querySelector('#play') every time, we just use playButton
        3. Error prevention: If we mistype an ID, we'll find out immediately when the page loads
      */
      let doodle = document.querySelector('#doodle');                         // The video display area where annotations are drawn
      let canvas = document.querySelector('#canvas');                         // The drawing surface overlaid on the video
      let ctx = canvas.getContext('2d');                                     // The "paintbrush" for drawing on the canvas
      let videoFile = document.querySelector('#videoFile');                   // File input for selecting video files
      let zipFile = document.querySelector('#zipFile');                       // File input for selecting ZIP archives
      let xmlFile = document.querySelector('#xmlFile');                       // File input for selecting XML annotation files
      let videoDimensionsElement = document.querySelector('#videoDimensions'); // Text area to show video size info
      let extractionProgressElement = document.querySelector('#extractionProgress'); // Text area to show extraction progress
      let downloadFramesButton = document.querySelector('#downloadFrames');   // Button to download extracted frames
      let playButton = document.querySelector('#play');                       // Play button (like on a video player)
      let pauseButton = document.querySelector('#pause');                     // Pause button (like on a video player)
      let speedInput = document.querySelector('#speed');                      // Input field for playback speed
      let sliderElement = document.querySelector('#slider');                  // Slider for scrubbing through video timeline
      let generateXmlButton = document.querySelector('#generateXml');         // Button to export annotations as XML
      let exportVideoButton = document.querySelector('#exportVideo');         // Button to export annotated video
      let exportAnnotatedZipButton = document.querySelector('#exportAnnotatedZip'); // Button to export annotated frames as ZIP
      let exportProgressDiv = document.querySelector('#exportProgress');      // Container for export progress display
      let exportProgressBar = document.querySelector('#exportProgressBar');   // Progress bar for export operations
      let exportProgressText = document.querySelector('#exportProgressText'); // Progress text for export operations

      // Advanced playback control buttons
      let skipToStartButton = document.querySelector('#skipToStart');         // Skip to start button
      let skip10FramesBackButton = document.querySelector('#skip10FramesBack'); // Skip 10 frames back button
      let skip1FrameBackButton = document.querySelector('#skip1FrameBack');   // Skip 1 frame back button
      let playPauseToggleButton = document.querySelector('#playPauseToggle'); // Play/pause toggle button
      let skip1FrameAheadButton = document.querySelector('#skip1FrameAhead'); // Skip 1 frame ahead button
      let skip10FramesAheadButton = document.querySelector('#skip10FramesAhead'); // Skip 10 frames ahead button
      let skipToEndButton = document.querySelector('#skipToEnd');             // Skip to end button

      /*
        CORE SYSTEM COMPONENTS - THE ENGINE AND TRACKER
        
        These are the two main "brains" of our application:
        
        1. framesManager: Think of this like a photo album manager. It knows how to:
           - Store all the individual frames from our video
           - Retrieve any specific frame when we need it
           - Keep track of how many frames we have total
        
        2. annotatedObjectsTracker: Think of this like a smart assistant who remembers:
           - Where each object (car, person, etc.) is in each frame
           - How objects move between frames using optical flow
           - Which annotations were drawn by humans vs. predicted by computer
        
        These work together like a librarian (framesManager) and a detective (annotatedObjectsTracker):
        - The librarian manages the photo collection
        - The detective analyzes the photos and tracks what's happening in them
      */
      let framesManager = new FramesManager();                               // Manages the collection of video frames
      let annotatedObjectsTracker = new AnnotatedObjectsTracker(framesManager); // Tracks objects across frames

      /*
        SLIDER CONTROL OBJECT - THE VIDEO TIMELINE SCRUBBER
        
        This object manages the horizontal slider that lets users scrub through the video
        timeline. Think of it like the progress bar on YouTube where you can:
        - Click and drag to jump to any point in the video
        - See where you currently are in the video
        - Enable/disable the slider when appropriate
        
        It's built using jQuery UI, which provides the fancy draggable slider functionality.
        We wrap it in our own object to make it easier to use and customize.
        
        The pattern here is called "object literal" - we create an object with several
        functions (methods) that all work together to manage one aspect of the UI.
      */
      let slider = {
        /*
          INITIALIZATION - SETTING UP THE SLIDER
          
          This function configures the slider with the video's frame range and sets up
          what happens when the user moves the slider.
          
          Parameters:
          - min: The first frame number (usually 0)
          - max: The last frame number (total frames - 1)
          - onChange: Function to call when user moves the slider
          
          Think of this like calibrating a speedometer in a car - you need to tell it
          what the minimum and maximum speeds are, and what to do when the needle moves.
        */
        init: function(min, max, onChange) {
          $(sliderElement).slider('option', 'min', min);     // Set the leftmost position value
          $(sliderElement).slider('option', 'max', max);     // Set the rightmost position value
          $(sliderElement).on('slidestop', (e, ui) => {      // When user stops dragging the slider
            onChange(ui.value);                              // Call the provided function with the new frame number
          });
          $(sliderElement).slider('enable');                 // Make the slider interactive
        },
        
        /*
          POSITION SETTER - MOVING THE SLIDER PROGRAMMATICALLY
          
          This function moves the slider to show the current frame position.
          It's like updating the position indicator on a video player to show
          where you are in the video.
          
          This is called "programmatically" because our code is moving the slider,
          not the user. When the video auto-plays, we need to update the slider
          position to match.
        */
        setPosition: function(frameNumber) {
          $(sliderElement).slider('option', 'value', frameNumber); // Move slider handle to this frame position
        },
        
        /*
          RESET - DISABLING THE SLIDER
          
          This function disables the slider and resets it to a default state.
          We do this when no video is loaded, or when we're in the middle of
          loading a new video.
          
          It's like graying out controls that can't be used right now.
        */
        reset: function() {
          $(sliderElement).slider({disabled: true}); // Make the slider unresponsive and visually disabled
        }
      };
      slider.reset(); // Start with the slider disabled (no video loaded yet)

      /*
        VIDEO PLAYER OBJECT - THE HEART OF VIDEO PLAYBACK CONTROL
        
        This object is like the engine of a video player (think YouTube or Netflix player).
        It manages all aspects of video playback:
        - Playing and pausing the video
        - Keeping track of which frame is currently displayed
        - Drawing frames with their annotations
        - Managing the timing of automatic playback
        
        Unlike a regular video player that plays actual video files, this player works
        with individual frame images and simulates video playback by showing them in sequence.
        
        Think of it like a digital flip-book player:
        - Each page is a frame
        - The player flips through pages at a controlled speed
        - It can start, stop, or jump to any specific page
        - It overlays drawings (annotations) on each page as it shows them
      */
      let player = {
        /*
          STATE VARIABLES - THE PLAYER'S MEMORY
          
          These variables keep track of the player's current state, like a car's dashboard
          that shows speed, fuel level, etc.
        */
        currentFrame: 0,      // Which frame are we currently showing? (like "page 42 of 100")
        isPlaying: false,     // Is the video currently playing? (like "engine running" indicator)
        isReady: false,       // Is the player ready to play? (like "engine warmed up" indicator)
        timeout: null,        // Timer for automatic frame advancement (like cruise control timer)

        /*
          INITIALIZATION - SETTING UP A FRESH PLAYER
          
          This function resets the player to its starting state, like turning off a car
          and resetting all the dashboard indicators to their default positions.
          
          Called when loading a new video or when the application starts up.
        */
        initialize: function() {
          this.currentFrame = 0;     // Start at the beginning (frame 0)
          this.isPlaying = false;    // Not playing yet
          this.isReady = false;      // Not ready until frames are loaded

          // Reset the UI buttons to their initial state
          playButton.disabled = true;        // Gray out play button (can't play until ready)
          playButton.style.display = 'block'; // Show the play button
          pauseButton.disabled = true;       // Gray out pause button
          pauseButton.style.display = 'none'; // Hide the pause button (only show one at a time)
        },

        /*
          READY STATE - ENABLING THE PLAYER
          
          This function is called when everything is loaded and the player is ready to work.
          It's like when your car has warmed up and all the dashboard lights indicate "ready to drive."
        */
        ready: function() {
          this.isReady = true;       // Mark the player as ready for use

          playButton.disabled = false; // Enable the play button (user can now click it)
          
          // Enable the new playback control buttons (with null checks for safety)
          if (skipToStartButton) skipToStartButton.disabled = false;
          if (skip10FramesBackButton) skip10FramesBackButton.disabled = false;
          if (skip1FrameBackButton) skip1FrameBackButton.disabled = false;
          if (playPauseToggleButton) playPauseToggleButton.disabled = false;
          if (skip1FrameAheadButton) skip1FrameAheadButton.disabled = false;
          if (skip10FramesAheadButton) skip10FramesAheadButton.disabled = false;
          if (skipToEndButton) skipToEndButton.disabled = false;
        },

        /*
          SEEK FUNCTION - JUMPING TO A SPECIFIC FRAME
          
          This is like using the "skip to chapter" function on a DVD player.
          The user can jump directly to any frame in the video without having to
          play through all the frames in between.
          
          Think of it like flipping directly to page 50 in a book instead of
          turning every page from 1 to 50.
          
          This function is called when:
          - User drags the timeline slider
          - User presses left/right arrow keys
          - User clicks on a specific frame number
        */
        seek: function(frameNumber) {
          if (!this.isReady) {       // Safety check: don't do anything if player isn't ready
            return;
          }

          this.pause();              // Stop any automatic playback first

          // Bounds checking: make sure the requested frame actually exists
          if (frameNumber >= 0 && frameNumber < framesManager.frames.totalFrames()) {
            this.drawFrame(frameNumber); // Display the requested frame
            this.currentFrame = frameNumber; // Update our position tracking
            
            // Update annotation manager with current frame
            if (window.annotationManager) {
              window.annotationManager.setCurrentFrame(frameNumber);
            }
          }
        },

        /*
          PLAY FUNCTION - STARTING AUTOMATIC PLAYBACK
          
          This starts the video playing automatically, like pressing the play button
          on any video player. It sets up a timer that will advance to the next frame
          at regular intervals, creating the illusion of smooth video playback.
          
          Think of it like setting up a metronome that will turn the pages of a
          flip-book at a steady rhythm.
        */
        play: function() {
          if (!this.isReady) {       // Safety check: don't do anything if player isn't ready
            return;
          }

          this.isPlaying = true;     // Mark that we're now in playing mode

          // Update the UI buttons: hide play button, show pause button
          playButton.disabled = true;        // Gray out play button
          playButton.style.display = 'none'; // Hide play button
          pauseButton.disabled = false;      // Enable pause button
          pauseButton.style.display = 'block'; // Show pause button

          this.nextFrame();          // Start the automatic frame advancement
        },

        /*
          PAUSE FUNCTION - STOPPING AUTOMATIC PLAYBACK
          
          This stops the automatic playback, like pressing the pause button on any
          video player. It cancels any pending frame advancement and updates the UI.
          
          Think of it like stopping the metronome that was turning flip-book pages.
        */
        pause: function() {
          if (!this.isReady) {       // Safety check: don't do anything if player isn't ready
            return;
          }

          this.isPlaying = false;    // Mark that we're no longer in playing mode
          
          // Cancel any pending frame advancement
          if (this.timeout != null) {
            clearTimeout(this.timeout); // Stop the timer
            this.timeout = null;         // Clear the timer reference
          }

          // Update the UI buttons: hide pause button, show play button
          pauseButton.disabled = true;       // Gray out pause button
          pauseButton.style.display = 'none'; // Hide pause button
          playButton.disabled = false;       // Enable play button
          playButton.style.display = 'block'; // Show play button
        },

        /*
          TOGGLE FUNCTION - PLAY/PAUSE SWITCHER
          
          This function switches between play and pause states, like a single
          play/pause button that changes behavior based on current state.
          
          It's called when the user presses the spacebar (common video player shortcut).
        */
        toogle: function() {         // Note: "toogle" is a typo in original code, should be "toggle"
          if (!this.isPlaying) {
            this.play();             // If paused, start playing
          } else {
            this.pause();            // If playing, pause
          }
        },

        /*
          NEXT FRAME FUNCTION - THE AUTOMATIC FRAME ADVANCEMENT ENGINE
          
          This is the "heartbeat" of video playback. It's called repeatedly while the video
          is playing to advance to the next frame. Think of it like the mechanism in a
          film projector that advances the film one frame at a time.
          
          The function:
          1. Checks if we should keep playing
          2. Checks if we've reached the end
          3. Displays the current frame
          4. Sets up a timer to call itself again for the next frame
          
          This creates a self-repeating cycle that simulates smooth video playback.
        */
        nextFrame: function() {
          if (!this.isPlaying) {     // If playback was stopped, don't continue
            return;
          }

          // Check if we've reached the end of the video
          if (this.currentFrame >= framesManager.frames.totalFrames()) {
            this.done();             // End of video reached, clean up and stop
            return;
          }

          // Display the current frame, then set up the next advancement
          this.drawFrame(this.currentFrame).then(() => {
            this.currentFrame++;     // Move to the next frame
            
            // Calculate delay until next frame based on FPS and speed settings
            // Formula: 1000ms ÷ (fps × speed) = delay in milliseconds
            // Example: 1000 ÷ (30 × 1.0) = 33.33ms delay (30 FPS)
            this.timeout = setTimeout(() => this.nextFrame(), 1000 / (config.fps * parseFloat(speedInput.value)));
          });
        },

        /*
          DRAW FRAME FUNCTION - THE VISUAL DISPLAY ENGINE
          
          This is one of the most important functions in the entire application. It's responsible
          for displaying a single frame with all its annotations. Think of it like a photographer's
          darkroom where multiple images (the base frame + annotation overlays) are combined
          into one final picture.
          
          What this function does:
          1. Gets the frame image and all object positions for this frame
          2. Draws the base image on the canvas
          3. Positions all the annotation boxes correctly
          4. Updates visibility states and UI controls
          5. Updates the timeline slider position
          
          This function is called:
          - When seeking to a specific frame
          - During automatic playback for each frame
          - When annotations are modified
          - When importing existing annotations
        */
        drawFrame: function(frameNumber) {
          return new Promise((resolve, _) => {
            // Get the frame image along with all object annotations for this frame
            annotatedObjectsTracker.getFrameWithObjects(frameNumber).then((frameWithObjects) => {
              /*
                DRAW THE BASE IMAGE
                
                First, we draw the actual video frame onto our canvas. This is like
                putting a photo onto a table before adding sticky notes on top.
              */
              ctx.drawImage(frameWithObjects.img, 0, 0);

              /*
                POSITION ALL ANNOTATION BOXES
                
                Now we go through each tracked object and position its visual bounding box
                to match where the object is in this frame. It's like moving sticky notes
                to the correct positions on our photo.
              */
              for (let i = 0; i < frameWithObjects.objects.length; i++) {
                let object = frameWithObjects.objects[i];           // Current object data
                let annotatedObject = object.annotatedObject;       // The object's complete annotation history
                let annotatedFrame = object.annotatedFrame;         // The object's position in this specific frame

                if (annotatedFrame.isVisible()) {
                  /*
                    OBJECT IS VISIBLE - SHOW AND POSITION THE BOUNDING BOX
                    
                    When an object is visible in this frame, we need to:
                    1. Make its bounding box visible
                    2. Resize it to match the object size
                    3. Position it correctly over the object
                    4. Update the visibility checkbox
                  */
                  annotatedObject.dom.style.display = 'block';      // Make the box visible
                  annotatedObject.dom.style.width = annotatedFrame.bbox.width + 'px';   // Set box width
                  annotatedObject.dom.style.height = annotatedFrame.bbox.height + 'px'; // Set box height
                  annotatedObject.dom.style.left = annotatedFrame.bbox.x + 'px';        // Position from left edge
                  annotatedObject.dom.style.top = annotatedFrame.bbox.y + 'px';         // Position from top edge
                  annotatedObject.visible.prop('checked', true);    // Check the visibility checkbox
                } else {
                  /*
                    OBJECT IS NOT VISIBLE - HIDE THE BOUNDING BOX
                    
                    When an object is not visible in this frame (went off-screen, behind
                    something, etc.), we hide its bounding box and uncheck its visibility.
                  */
                  annotatedObject.dom.style.display = 'none';       // Hide the box
                  annotatedObject.visible.prop('checked', false);   // Uncheck the visibility checkbox
                }
              }

              /*
                HANDLE "HIDE OTHERS" FEATURE
                
                Some objects might have a "hide others" flag set. This is useful when you want
                to focus on just one object and hide all the rest. It's like putting a spotlight
                on one actor while dimming the lights on everyone else.
              */
              let shouldHideOthers = frameWithObjects.objects.some(o => o.annotatedObject.hideOthers);
              if (shouldHideOthers) {
                // Go through all objects and hide those that don't have the "hideOthers" flag
                for (let i = 0; i < frameWithObjects.objects.length; i++) {
                  let object = frameWithObjects.objects[i];
                  let annotatedObject = object.annotatedObject;
                  if (!annotatedObject.hideOthers) {
                    annotatedObject.dom.style.display = 'none'; // Hide this object's bounding box
                  }
                }
              }

              /*
                UPDATE TIMELINE SLIDER
                
                Move the timeline slider to show the current frame position.
                This keeps the slider in sync with what's being displayed.
              */
              slider.setPosition(this.currentFrame);

              resolve(); // Signal that we're done drawing this frame
            });
          });
        },

        /*
          DONE FUNCTION - END OF VIDEO CLEANUP
          
          This function is called when the video reaches the end during automatic playback.
          It resets the player to a stopped state and prepares for potential replay.
          
          Think of it like what happens when a DVD reaches the end - it stops playing
          and returns to a state where you can press play again.
        */
        done: function() {
          this.currentFrame = 0;     // Reset to the beginning for potential replay
          this.isPlaying = false;    // Mark as stopped

          // Reset UI buttons to stopped state
          playButton.disabled = false;        // Enable play button
          playButton.style.display = 'block'; // Show play button
          pauseButton.disabled = true;        // Disable pause button
          pauseButton.style.display = 'none'; // Hide pause button
        }
      };

      /*
        ANNOTATION CLEANUP FUNCTIONS - THE HOUSEKEEPING CREW
        
        These functions handle cleaning up annotation data when needed. Think of them
        like a cleaning crew that tidies up after a party - they remove objects that
        are no longer needed and free up memory.
        
        This is important because:
        1. Memory management: Removing unused objects prevents memory leaks
        2. UI cleanup: Removing DOM elements prevents visual clutter
        3. Data integrity: Ensuring the annotation list stays synchronized with what's actually displayed
      */

      /*
        CLEAR ALL ANNOTATED OBJECTS - THE COMPLETE RESET
        
        This function removes all annotations from the system. It's like erasing all
        the sticky notes from a photo and starting with a clean slate.
        
        Called when:
        - Loading a new video file
        - Resetting the application
        - Starting a fresh annotation session
      */
      function clearAllAnnotatedObjects() {
        // Go through each annotated object and clean it up individually
        // We need to work backwards or use while loop since clearAnnotatedObject modifies the array
        while (annotatedObjectsTracker.annotatedObjects.length > 0) {
          clearAnnotatedObject(0); // Always remove the first element
        }
      }

      /*
        CLEAR SINGLE ANNOTATED OBJECT - TARGETED CLEANUP
        
        This function removes one specific annotation object. It's like removing
        one specific sticky note from a photo while leaving all the others.
        
        The cleanup process involves:
        1. Removing the UI controls (name input, checkboxes, etc.)
        2. Removing the visual bounding box from the screen
        3. Removing the object from our tracking list
      */
      function clearAnnotatedObject(i) {
        let annotatedObject = annotatedObjectsTracker.annotatedObjects[i]; // Get the object to remove
        
        annotatedObject.controls.remove();  // Remove the UI control panel (jQuery removal)
        $(annotatedObject.dom).remove();    // Remove the visual bounding box (jQuery removal)
        annotatedObjectsTracker.annotatedObjects.splice(i, 1); // Remove from our tracking array
      }

      /*
        EVENT LISTENER SETUP - CONNECTING USER ACTIONS TO FUNCTIONS
        
        These lines set up "event listeners" - they're like hiring security guards to watch
        specific doors and call specific people when someone enters. Each event listener
        watches for a specific user action and calls a specific function when it happens.
        
        Think of it like programming a smart home system:
        - "When the doorbell rings, turn on the porch light"
        - "When someone opens the fridge, turn on the inside light"
        - "When the file input changes, call the extraction function"
        
        The 'false' parameter is a technical detail about event handling (it means "don't capture").
      */
      videoFile.addEventListener('change', extractionFileUploaded, false);    // When user selects a video file
      zipFile.addEventListener('change', extractionFileUploaded, false);      // When user selects a ZIP file
      xmlFile.addEventListener('change', importXml, false);                   // When user selects an XML file
      playButton.addEventListener('click', playClicked, false);               // When user clicks play button
      pauseButton.addEventListener('click', pauseClicked, false);             // When user clicks pause button
      downloadFramesButton.addEventListener('click', downloadFrames, false);  // When user clicks download button
      generateXmlButton.addEventListener('click', generateXml, false);        // When user clicks XML export button

      /*
        ADVANCED PLAYBACK CONTROL EVENT LISTENERS
        
        These connect the new playback control buttons to their respective functions
      */
      // Add event listeners for the new buttons
      skipToStartButton.addEventListener('click', skipToStartClicked, false);
      skip10FramesBackButton.addEventListener('click', skip10FramesBackClicked, false);
      skip1FrameBackButton.addEventListener('click', skip1FrameBackClicked, false);
      playPauseToggleButton.addEventListener('click', playPauseToggleClicked, false);
      skip1FrameAheadButton.addEventListener('click', skip1FrameAheadClicked, false);
      skip10FramesAheadButton.addEventListener('click', skip10FramesAheadClicked, false);
      skipToEndButton.addEventListener('click', skipToEndClicked, false);

      /*
        SIMPLE BUTTON CLICK HANDLERS - THE DELEGATION FUNCTIONS
        
        These are simple "wrapper" functions that just call the appropriate player methods.
        You might wonder "why not connect the event listeners directly to player.play()?"
        
        The reason is that event listeners pass extra parameters (event objects) to functions,
        but our player methods don't expect those parameters. These wrapper functions act
        like translators that convert "user clicked play button" into "player.play()".
        
        Think of them like receptionists who take messages and relay them to the right person
        in the right format.
      */
      function playClicked() {
        player.play();    // Tell the player to start playing
      }

      function pauseClicked() {
        player.pause();   // Tell the player to pause
      }

      /*
        ADVANCED PLAYBACK CONTROL HANDLERS
        
        These functions handle the new playback control buttons with frame-specific navigation
      */
      function skipToStartClicked() {
        console.log('Skip to start clicked'); // Debug log
        if (player && player.seek) {
          player.seek(0); // Jump to the first frame
        }
      }

      function skip10FramesBackClicked() {
        console.log('Skip 10 frames back clicked, current frame:', player.currentFrame); // Debug log
        if (player && player.seek && player.currentFrame !== undefined) {
          const newFrame = Math.max(player.currentFrame - 10, 0);
          player.seek(newFrame); // Jump 10 frames back, ensuring it doesn't go below 0
        }
      }

      function skip1FrameBackClicked() {
        console.log('Skip 1 frame back clicked, current frame:', player.currentFrame); // Debug log
        if (player && player.seek && player.currentFrame !== undefined) {
          const newFrame = Math.max(player.currentFrame - 1, 0);
          player.seek(newFrame); // Jump 1 frame back, ensuring it doesn't go below 0
        }
      }

      function playPauseToggleClicked() {
        console.log('Play/Pause toggle clicked'); // Debug log
        if (player && player.toogle) {
          player.toogle(); // Toggle between play and pause (note: keeping original typo)
        }
      }

      function skip1FrameAheadClicked() {
        console.log('Skip 1 frame ahead clicked, current frame:', player.currentFrame); // Debug log
        if (player && player.seek && player.currentFrame !== undefined && framesManager && framesManager.frames) {
          const newFrame = Math.min(player.currentFrame + 1, framesManager.frames.totalFrames() - 1);
          player.seek(newFrame); // Jump 1 frame ahead, ensuring it doesn't go beyond last frame
        }
      }

      function skip10FramesAheadClicked() {
        console.log('Skip 10 frames ahead clicked, current frame:', player.currentFrame); // Debug log
        if (player && player.seek && player.currentFrame !== undefined && framesManager && framesManager.frames) {
          const newFrame = Math.min(player.currentFrame + 10, framesManager.frames.totalFrames() - 1);
          player.seek(newFrame); // Jump 10 frames ahead, ensuring it doesn't go beyond last frame
        }
      }

      function skipToEndClicked() {
        console.log('Skip to end clicked'); // Debug log
        if (player && player.seek && framesManager && framesManager.frames) {
          const lastFrame = framesManager.frames.totalFrames() - 1;
          player.seek(lastFrame); // Jump to the last frame
        }
      }

      /*
        DOWNLOAD FRAMES FUNCTION - THE FRAME PACKAGER
        
        This function takes all the extracted video frames and packages them into a
        downloadable ZIP file. Think of it like taking all the pages from a disassembled
        flip-book and putting them in an envelope to mail to someone.
        
        The process:
        1. Create a new ZIP file container
        2. Go through each frame in our collection
        3. Add each frame to the ZIP with a sequential filename
        4. When all frames are added, generate the final ZIP file
        5. Trigger a download to the user's computer
        
        This is useful for:
        - Backing up extracted frames
        - Sharing frames with other people
        - Using frames in other video editing software
        - Manual inspection of individual frames
      */
      function downloadFrames() {
        let zip = new JSZip(); // Create a new ZIP file container (like getting an empty box)

        let processed = 0; // Counter to track how many frames we've processed
        let totalFrames = framesManager.frames.totalFrames(); // Get total number of frames
        
        /*
          FRAME PROCESSING LOOP
          
          We go through each frame and add it to the ZIP. This is done asynchronously
          because getting frame data takes time (it might be stored in a database).
          
          Think of it like an assembly line where workers add items to boxes, but each
          worker might take different amounts of time to complete their task.
        */
        for (let i = 0; i < totalFrames; i++) {
          framesManager.frames.getFrame(i).then((blob) => { // Get frame data as a blob
            zip.file(i + '.jpg', blob); // Add this frame to the ZIP with filename "0.jpg", "1.jpg", etc.

            processed++; // Increment our completion counter
            
            /*
              CHECK IF ALL FRAMES ARE PROCESSED
              
              When we've processed all frames, generate and download the ZIP file.
              We can't do this earlier because the frame processing is asynchronous
              (they might finish in a different order than they started).
            */
            if (processed == totalFrames) {
              /*
                GENERATE AND DOWNLOAD THE ZIP FILE
                
                This creates a streaming download - the ZIP file is generated and
                downloaded in chunks rather than loading everything into memory at once.
                This prevents memory issues with large videos.
              */
              let writeStream = streamSaver.createWriteStream('extracted-frames.zip').getWriter();
              zip.generateInternalStream({type: 'uint8array', streamFiles: true})
                 .on('data', data => writeStream.write(data))  // Write each chunk as it's generated
                 .on('end', () => writeStream.close())         // Close the file when done
                 .resume(); // Start the streaming process
            }
          });
        }
      }

      /*
        CANVAS DIMENSION INITIALIZATION - SETTING UP THE DRAWING AREA
        
        This function sets up the video display area to match the dimensions of the video.
        Think of it like choosing the right size picture frame for a photo - the frame
        needs to be exactly the right size or the photo won't fit properly.
        
        Why is this important?
        1. The canvas must match the video size for annotations to align correctly
        2. The container must be sized properly for the user interface to look right
        3. The slider width should match the video width for visual consistency
        
        This function is called whenever we load a new video, because different videos
        might have different dimensions (1920x1080, 640x480, etc.).
      */
      function initializeCanvasDimensions(img) {
        /*
          SET CONTAINER DIMENSIONS
          
          The 'doodle' container holds the video canvas and annotation overlays.
          We set its size to match the video so everything fits properly.
        */
        doodle.style.width = img.width + 'px';   // Set container width to match video
        doodle.style.height = img.height + 'px'; // Set container height to match video
        
        /*
          SET CANVAS DIMENSIONS
          
          The canvas is where we draw the video frames. It must be exactly the same
          size as the video or the images will be stretched or cropped.
        */
        canvas.width = img.width;   // Set canvas pixel width
        canvas.height = img.height; // Set canvas pixel height
        
        /*
          SET SLIDER WIDTH
          
          Make the timeline slider the same width as the video for visual consistency.
          This creates a pleasing aligned layout where the slider spans the full video width.
        */
        sliderElement.style.width = img.width + 'px';
      }

      /*
        FILE UPLOAD HANDLER - THE MAIN WORKFLOW COORDINATOR
        
        This is one of the most important functions in the application. It handles what happens
        when a user selects a file (either video or ZIP). Think of it like the main conductor
        of an orchestra - it coordinates all the different parts to work together in the right sequence.
        
        The workflow:
        1. Disable all controls while processing (prevent user from breaking things)
        2. Clear any existing annotations (start fresh)
        3. Reset the player and interface
        4. Determine file type and extract frames accordingly
        5. Set up the interface for annotation work
        6. Re-enable appropriate controls
        
        This function is called by the event listeners when videoFile or zipFile inputs change.
        The 'this' keyword refers to whichever file input triggered the event.
      */
      function extractionFileUploaded() {
        /*
          SAFETY CHECK - ENSURE ONE FILE SELECTED
          
          Make sure the user actually selected a file. The files array might be empty
          if the user opened the file dialog but then cancelled without selecting anything.
        */
        if (this.files.length != 1) {
          return; // Exit early if no file or multiple files selected
        }

        /*
          DISABLE ALL CONTROLS - PREVENT USER INTERFERENCE
          
          While we're processing the file, we disable all the buttons and inputs to prevent
          the user from clicking things that might interfere with the process. It's like
          putting up "Under Construction" signs around a work area.
          
          This prevents confusing situations like:
          - User clicking play while frames are still being extracted
          - User loading a second file while the first is still processing
          - User trying to export annotations before any exist
        */
        videoFile.disabled = true;               // Disable video file input
        zipFile.disabled = true;                 // Disable ZIP file input
        xmlFile.disabled = true;                 // Disable XML file input
        downloadFramesButton.disabled = true;   // Disable download button
        generateXmlButton.disabled = true;      // Disable XML export button
        exportVideoButton.disabled = true;      // Disable video export button
        exportAnnotatedZipButton.disabled = true; // Disable annotated ZIP export button
        
        /*
          CLEAN SLATE PREPARATION
          
          Clear any existing work and reset the interface to prepare for the new file.
          This ensures we don't have leftover data from a previous session interfering
          with the new file.
        */
        clearAllAnnotatedObjects(); // Remove all existing annotations
        slider.reset();              // Disable and reset the timeline slider
        player.initialize();         // Reset the player to initial state

        /*
          DETERMINE FILE TYPE AND PROCESSING METHOD
          
          We need to handle video files and ZIP files differently:
          - Video files: Extract frames using the video processing engine
          - ZIP files: Read pre-extracted frames from the archive
          
          We determine which type by checking which input element triggered this function.
        */
        let promise; // Variable to hold the extraction promise
        
        if (this == videoFile) {
          /*
            VIDEO FILE PROCESSING BRANCH
            
            When processing a video file, we need to:
            1. Extract individual frames from the video
            2. Show progress to the user
            3. Display preview frames as they're processed
            4. Handle dimension detection
          */
          let dimensionsInitialized = false; // Flag to track if we've set up canvas dimensions

          promise = extractFramesFromVideo(
            config,           // Configuration settings
            this.files[0],    // The selected video file
            /*
              PROGRESS CALLBACK FUNCTION
              
              This function is called repeatedly during extraction to show progress.
              It receives information about how much work is done and the latest frame.
              
              Think of it like a construction foreman calling you every hour to say
              "We're 25% done, and here's a photo of the current progress."
            */
            (percentage, framesSoFar, lastFrameBlob) => {
              // Convert the latest frame blob to an image we can display
              blobToImage(lastFrameBlob).then((img) => {
                /*
                  FIRST FRAME DIMENSION SETUP
                  
                  When we get the first frame, we use it to set up the canvas dimensions.
                  We only do this once (hence the flag) because all frames should have
                  the same dimensions.
                */
                if (!dimensionsInitialized) {
                  dimensionsInitialized = true;
                  initializeCanvasDimensions(img); // Set up canvas to match video size
                }
                
                ctx.drawImage(img, 0, 0); // Display the latest frame as a preview

                /*
                  UPDATE PROGRESS DISPLAYS
                  
                  Show the user how the extraction is progressing with both text updates.
                  This keeps them informed and prevents them from thinking the app is frozen.
                */
                videoDimensionsElement.innerHTML = 'Video dimensions determined: ' + img.width + 'x' + img.height;
                extractionProgressElement.innerHTML = (percentage * 100).toFixed(2) + ' % completed. ' + framesSoFar + ' frames extracted.';
              });
            });
        } else {
          /*
            ZIP FILE PROCESSING BRANCH
            
            When processing a ZIP file, the frames are already extracted, so we just
            need to read them from the archive. This is much faster than video extraction.
          */
          promise = extractFramesFromZip(config, this.files[0]);
        }

        /*
          POST-EXTRACTION PROCESSING - SETTING UP FOR ANNOTATION WORK
          
          When the frame extraction is complete (either from video or ZIP), we need to
          set up the interface for annotation work. This is like setting up all your
          art supplies after you've gotten your canvas ready.
          
          The .then() means "when the extraction promise is complete, do this..."
        */
        promise.then((frames) => {
          /*
            UPDATE COMPLETION STATUS
            
            Show the user that extraction is complete and how many frames were found.
          */
          extractionProgressElement.innerHTML = 'Extraction completed. ' + frames.totalFrames() + ' frames captured.';
          
          /*
            SETUP FOR ANNOTATION WORK - BUT ONLY IF WE HAVE FRAMES
            
            If the extraction found at least one frame, set up the interface for annotation.
            If no frames were found, skip this setup (empty video or corrupted file).
          */
          if (frames.totalFrames() > 0) {
            /*
              DISPLAY THE FIRST FRAME
              
              Show the first frame of the video as a starting point. This gives the user
              something to look at and lets them see what they'll be working with.
            */
            frames.getFrame(0).then((blob) => {
              blobToImage(blob).then((img) => {
                /*
                  FINAL SETUP STEPS
                  
                  Complete the interface setup now that we have frame data.
                */
                initializeCanvasDimensions(img); // Set canvas dimensions (in case this wasn't done during progress)
                ctx.drawImage(img, 0, 0);        // Display the first frame
                videoDimensionsElement.innerHTML = 'Video dimensions determined: ' + img.width + 'x' + img.height;

                /*
                  CONNECT THE FRAME MANAGER
                  
                  Give our frames to the frame manager. This triggers any reset callbacks
                  and makes the frames available to the rest of the application.
                */
                framesManager.set(frames);
                
                /*
                  INITIALIZE THE TIMELINE SLIDER
                  
                  Set up the slider to span from frame 0 to the last frame, and define
                  what happens when the user moves it (seek to that frame).
                */
                slider.init(
                  0,                                    // Minimum value (first frame)
                  framesManager.frames.totalFrames() - 1, // Maximum value (last frame)
                  (frameNumber) => player.seek(frameNumber) // What to do when slider moves
                );
                
                /*
                  ENABLE THE PLAYER
                  
                  Mark the player as ready for use. This enables the play button and
                  allows the user to start interacting with the video.
                */
                player.ready();

                /*
                  RE-ENABLE INTERFACE CONTROLS
                  
                  Now that everything is set up, re-enable all the controls that we
                  disabled at the beginning. The user can now start annotating!
                */
                xmlFile.disabled = false;                // Allow XML import
                playButton.disabled = false;             // Allow video playback
                downloadFramesButton.disabled = false;   // Allow frame download
                generateXmlButton.disabled = false;      // Allow XML export
                exportVideoButton.disabled = false;      // Allow video export
                exportAnnotatedZipButton.disabled = false; // Allow annotated ZIP export
                
                // Enable the new playback control buttons (with null checks for safety)
                if (skipToStartButton) skipToStartButton.disabled = false;
                if (skip10FramesBackButton) skip10FramesBackButton.disabled = false;
                if (skip1FrameBackButton) skip1FrameBackButton.disabled = false;
                if (playPauseToggleButton) playPauseToggleButton.disabled = false;
                if (skip1FrameAheadButton) skip1FrameAheadButton.disabled = false;
                if (skip10FramesAheadButton) skip10FramesAheadButton.disabled = false;
                if (skipToEndButton) skipToEndButton.disabled = false;
              });
            });
          }

          /*
            FINAL CLEANUP - RE-ENABLE FILE INPUTS
            
            Re-enable the file input controls so the user can load a different file if needed.
            We do this regardless of whether frame extraction was successful or not.
          */
          videoFile.disabled = false; // Re-enable video file input
          zipFile.disabled = false;   // Re-enable ZIP file input
        });
      }

      /*
        INTERACTIFY FUNCTION - MAKING BOUNDING BOXES INTERACTIVE
        
        This function takes a static HTML element and makes it into an interactive bounding box
        that users can resize and drag around. Think of it like turning a picture frame into
        a smart picture frame that can resize itself and move around on the wall.
        
        What this function adds:
        1. Resize handles on the edges (like corner handles on a window)
        2. Drag capability (like being able to move the whole window)
        3. Containment (can't be dragged outside the video area)
        4. Callback function when changes are made
        
        This uses jQuery UI widgets (resizable and draggable) to provide the interactive functionality.
        It's like installing power steering and power windows in a basic car.
      */
      function interactify(dom, onChange) {
        let bbox = $(dom); // Convert to jQuery object for easier manipulation
        bbox.addClass('bbox'); // Add CSS class for styling

        /*
          CREATE RESIZE HANDLE HELPER FUNCTION
          
          This helper function creates the small visual handles that appear on the edges
          of a bounding box for resizing. Think of them like the little squares that
          appear on the corners of a selected image in a word processor.
        */
        let createHandleDiv = (className) => {
          let handle = document.createElement('div'); // Create a new div element
          handle.className = className;               // Set its CSS class for styling
          bbox.append(handle);                        // Add it to the bounding box
          return handle;                              // Return the handle for use
        };

        /*
          MAKE THE BOUNDING BOX RESIZABLE
          
          This adds resize functionality to the bounding box. Users can drag the edges
          to make it bigger or smaller, like resizing a window.
        */
        bbox.resizable({
          containment: 'parent', // Can't resize outside the video area
          handles: {
            // Create handles for each edge: North, South, East, West
            n: createHandleDiv('ui-resizable-handle ui-resizable-n'), // Top edge
            s: createHandleDiv('ui-resizable-handle ui-resizable-s'), // Bottom edge
            e: createHandleDiv('ui-resizable-handle ui-resizable-e'), // Right edge
            w: createHandleDiv('ui-resizable-handle ui-resizable-w')  // Left edge
          },
          /*
            RESIZE COMPLETION CALLBACK
            
            When the user finishes resizing, get the new position and size and
            call the onChange function to update the annotation data.
          */
          stop: (e, ui) => {
            let position = bbox.position(); // Get current position
            // Call onChange with rounded values (pixels should be whole numbers)
            onChange(Math.round(position.left), Math.round(position.top), Math.round(bbox.width()), Math.round(bbox.height()));
          }
        });

        /*
          MAKE THE BOUNDING BOX DRAGGABLE
          
          This allows users to drag the entire bounding box to a new position,
          like moving a sticky note to a different part of a photo.
        */
        bbox.draggable({
          containment: 'parent', // Can't drag outside the video area
          handle: createHandleDiv('handle center-drag'), // Create a central drag handle
          /*
            DRAG COMPLETION CALLBACK
            
            When the user finishes dragging, get the new position and call
            the onChange function to update the annotation data.
          */
          stop: (e, ui) => {
            let position = bbox.position(); // Get new position
            // Call onChange with current position and unchanged size
            onChange(Math.round(position.left), Math.round(position.top), Math.round(bbox.width()), Math.round(bbox.height()));
          }
        });
      }

      /*
        MOUSE TRACKING OBJECT - THE CURSOR POSITION MONITOR
        
        This object keeps track of where the mouse cursor is positioned within the video area.
        Think of it like having a GPS system that always knows exactly where you are on a map.
        
        Why do we need this?
        When users are drawing bounding boxes, we need to know:
        1. Where they first clicked (starting corner)
        2. Where they're currently dragging to (current corner)
        3. The difference between these points (the box size)
        
        We store both current position and starting position so we can calculate
        the bounding box dimensions as the user drags.
      */
      let mouse = {
        x: 0,      // Current mouse X position relative to the video
        y: 0,      // Current mouse Y position relative to the video
        startX: 0, // X position where user first clicked to start drawing
        startY: 0  // Y position where user first clicked to start drawing
      };

      /*
        TEMPORARY ANNOTATION OBJECT - THE WORK-IN-PROGRESS TRACKER
        
        When a user is in the middle of drawing a new bounding box, we need to track
        the box being created before it becomes a "real" annotation. This variable
        holds that temporary box.
        
        Think of it like a rough sketch that you're working on before making it into
        a final drawing. When it's null, no box is being drawn. When it has a value,
        the user is actively drawing a box.
      */
      let tmpAnnotatedObject = null;

      /*
        MOUSE MOVE EVENT HANDLER - THE REAL-TIME POSITION TRACKER
        
        This function is called every time the mouse moves over the video area. It's like
        having a motion sensor that constantly reports "now the mouse is here, now it's here."
        
        The function does two main things:
        1. Updates our mouse position tracking (for all interactions)
        2. If a bounding box is being drawn, updates its size in real-time
        
        This creates the "rubber band" effect where you can see the box growing and
        shrinking as you drag the mouse around.
      */
      doodle.onmousemove = function (e) {
        /*
          CROSS-BROWSER MOUSE POSITION DETECTION
          
          Different browsers provide mouse position information in slightly different ways.
          This code tries multiple methods to ensure it works everywhere.
          
          Think of it like asking for directions in a foreign country - you try different
          ways of asking until someone understands and gives you the information you need.
        */
        let ev = e || window.event; // Get the event object (cross-browser compatible)
        
        if (ev.pageX) {
          // Method 1: pageX/pageY (most modern browsers)
          mouse.x = ev.pageX;
          mouse.y = ev.pageY;
        } else if (ev.clientX) {
          // Method 2: clientX/clientY (older browsers)
          mouse.x = ev.clientX;
          mouse.y = ev.clientY;
        }
        
        /*
          CONVERT TO VIDEO-RELATIVE COORDINATES
          
          The mouse positions we got above are relative to the entire webpage, but we need
          positions relative to just the video area. We subtract the video area's position
          to get local coordinates.
          
          Think of it like converting from "5 miles east of the city center" to 
          "5 blocks east of our neighborhood."
        */
        mouse.x -= doodle.offsetLeft; // Subtract video area's left offset
        mouse.y -= doodle.offsetTop;  // Subtract video area's top offset

        /*
          REAL-TIME BOUNDING BOX DRAWING UPDATE
          
          If the user is currently drawing a bounding box (tmpAnnotatedObject exists),
          update its size and position based on the current mouse position.
          
          This creates the visual feedback where the box stretches as you drag.
        */
        if (tmpAnnotatedObject !== null) {
          /*
            CALCULATE BOX DIMENSIONS
            
            The bounding box size is the distance between where the user first clicked
            (startX, startY) and where the mouse currently is (x, y).
            
            We use Math.abs() because the user might drag in any direction, and we
            always want positive width and height values.
          */
          tmpAnnotatedObject.width = Math.abs(mouse.x - mouse.startX);   // Distance horizontally
          tmpAnnotatedObject.height = Math.abs(mouse.y - mouse.startY);  // Distance vertically
          
          /*
            CALCULATE BOX POSITION
            
            The box position (top-left corner) depends on which direction the user dragged.
            If they dragged up and to the left, the current mouse position becomes the
            top-left corner. If they dragged down and to the right, the starting position
            is the top-left corner.
            
            This ensures the box always appears in the right place regardless of drag direction.
          */
          tmpAnnotatedObject.x = (mouse.x - mouse.startX < 0) ? mouse.x : mouse.startX;     // Leftmost position
          tmpAnnotatedObject.y = (mouse.y - mouse.startY < 0) ? mouse.y : mouse.startY;     // Topmost position

          /*
            UPDATE THE VISUAL BOUNDING BOX
            
            Apply the calculated dimensions and position to the actual HTML element
            so the user can see the box being drawn in real-time.
          */
          tmpAnnotatedObject.dom.style.width = tmpAnnotatedObject.width + 'px';   // Set visual width
          tmpAnnotatedObject.dom.style.height = tmpAnnotatedObject.height + 'px'; // Set visual height
          tmpAnnotatedObject.dom.style.left = tmpAnnotatedObject.x + 'px';        // Set visual X position
          tmpAnnotatedObject.dom.style.top = tmpAnnotatedObject.y + 'px';         // Set visual Y position
        }
      }

      /*
        MOUSE CLICK EVENT HANDLER - THE ANNOTATION CREATION CONTROLLER
        
        This is one of the most complex and important functions in the application. It handles
        the two-click process for creating new bounding box annotations. Think of it like a
        state machine that manages the annotation creation workflow.
        
        The Two-Click Process:
        1. First click: Start drawing a new bounding box (if in crosshair mode)
        2. Second click: Finalize the bounding box and create the annotation
        
        The function behaves differently depending on the current state:
        - If cursor is not in crosshair mode: Do nothing (normal cursor behavior)
        - If no box is being drawn: Start drawing a new box
        - If a box is being drawn: Finish the box and create the annotation
        
        This is like having a drawing tool that works in two steps: "start drawing" and "finish drawing."
      */
      doodle.onclick = function (e) {
        /*
          MODE CHECK - ONLY WORK IN ANNOTATION MODE
          
          Only proceed if the cursor is in "crosshair" mode, which indicates the user
          is ready to create annotations. If the cursor is normal, the user is just
          navigating and we shouldn't create annotations on random clicks.
        */
        if (doodle.style.cursor != 'crosshair') {
          return; // Exit early if not in annotation mode
        }

        if (tmpAnnotatedObject != null) {
          /*
            SECOND CLICK - FINALIZE THE ANNOTATION
            
            The user has finished drawing the bounding box and clicked to complete it.
            Now we need to convert the temporary drawing into a real annotation object.
          */
          
          // Create a new permanent annotation object
          let annotatedObject = new AnnotatedObject();
          annotatedObject.dom = tmpAnnotatedObject.dom; // Use the visual element we created
          
          // Get the currently selected class and assign it to the annotation
          const selectedClass = getCurrentAnnotationClass();
          if (selectedClass) {
            annotatedObject.className = selectedClass;
            annotatedObject.color = getClassColor(selectedClass);
            
            // Update the visual element color
            tmpAnnotatedObject.dom.style.borderColor = annotatedObject.color;
          } else {
            annotatedObject.color = '#FF0000'; // Set default red color for new annotations
          }
          
          // Create the bounding box data structure
          let bbox = new BoundingBox(tmpAnnotatedObject.x, tmpAnnotatedObject.y, tmpAnnotatedObject.width, tmpAnnotatedObject.height);
          
          // Create an annotation frame for the current frame (marked as ground truth because human-created)
          annotatedObject.add(new AnnotatedFrame(player.currentFrame, bbox, true));
          
          // Add the object to our tracking system
          annotatedObjectsTracker.annotatedObjects.push(annotatedObject);
          
          // Create annotation card in the individual annotations UI
          if (window.annotationManager) {
            const classInfo = selectedClass ? {
              name: selectedClass,
              color: annotatedObject.color
            } : null;
            
            window.annotationManager.createAnnotationCard(annotatedObject, classInfo);
          }
          
          // Clear the temporary object (we're done with it)
          tmpAnnotatedObject = null;

          /*
            MAKE THE ANNOTATION INTERACTIVE
            
            Enable resize and drag functionality for the newly created annotation.
            The onChange callback updates the annotation when the user modifies it.
          */
          interactify(
            annotatedObject.dom,
            (x, y, width, height) => {
              let bbox = new BoundingBox(x, y, width, height);
              annotatedObject.add(new AnnotatedFrame(player.currentFrame, bbox, true));
            }
          );

          // Add UI controls for this annotation (name, visibility, etc.)
          addAnnotatedObjectControls(annotatedObject);

          // Return cursor to normal mode (annotation creation complete)
          doodle.style.cursor = 'default';
        } else {
          /*
            FIRST CLICK - START DRAWING A NEW ANNOTATION
            
            The user wants to start drawing a new bounding box. Record the starting
            position and create a temporary visual element.
          */
          
          // Record where the user clicked as the starting corner
          mouse.startX = mouse.x;
          mouse.startY = mouse.y;

          // Create a new visual bounding box element
          let dom = newBboxElement();
          dom.style.left = mouse.x + 'px';  // Position at click location
          dom.style.top = mouse.y + 'px';   // Position at click location
          
          // Create temporary object to track the drawing process
          tmpAnnotatedObject = { dom: dom };
        }
      }

      /*
        NEW BOUNDING BOX ELEMENT FACTORY - THE BOX CREATOR
        
        This function creates a new visual bounding box element that will appear on screen.
        Think of it like a factory that stamps out identical rectangular frames that can
        be placed over objects in the video.
        
        The process:
        1. Create a new HTML div element (like cutting out a rectangular piece of paper)
        2. Give it the 'bbox' CSS class for styling (like coloring the paper border red)
        3. Add it to the video display area (like placing the paper frame on top of a photo)
        4. Return the element so other code can position and size it
      */
      function newBboxElement() {
          let dom = document.createElement('div'); // Create a new rectangular HTML element
          dom.className = 'bbox';                  // Apply the bounding box CSS styling
          doodle.appendChild(dom);                 // Add it to the video display area
          return dom;                              // Give back the element for further use
      }

      /*
        ADD ANNOTATION CONTROLS - THE CONTROL PANEL CREATOR
        
        This function creates a complete control panel for managing a single annotation.
        Think of it like building a dashboard for each annotated object, with buttons,
        text boxes, and switches that let the user control that specific annotation.
        
        For each annotation, we create:
        1. Name input field - what to call this object ("car", "person", etc.)
        2. ID input field - unique identifier for tracking
        3. Visibility checkbox - show/hide this annotation
        4. "Hide others" checkbox - focus mode to show only this annotation
        5. Delete button - remove this annotation completely
        
        All these controls are packaged together in a bordered box and added to the
        controls area of the interface.
        
        Think of it like creating a remote control that's specifically designed to
        operate one TV - each annotation gets its own custom remote control.
      */
      function addAnnotatedObjectControls(annotatedObject) {
        /*
          CREATE NAME INPUT FIELD - THE OBJECT LABEL EDITOR
          
          This creates a text input where users can type what kind of object this is.
          Think of it like a name tag that you can write on - "Hello, my name is ____"
          
          Default value is "Name?" to prompt the user to change it.
          We listen for any kind of text change (typing, pasting, etc.) and immediately
          save the new name to the annotation object.
        */
        let name = $('<input type="text" value="Name?" />');
        if (annotatedObject.name) {          // If the object already has a name
          name.val(annotatedObject.name);    // Pre-fill the input with the existing name
        }
        name.on('change keyup paste mouseup', function() {
          annotatedObject.name = this.value; // Save any changes immediately
        });

        /*
          CREATE CLASS DROPDOWN - THE OBJECT CATEGORY SELECTOR
          
          This creates a dropdown where users can select which class/category this
          annotation belongs to. Think of it like sorting items into labeled boxes -
          "Vehicles", "People", "Buildings", etc.
          
          When a class is selected:
          1. The annotation gets assigned a class name
          2. The bounding box color changes to match the class color
          3. The control panel border updates to match the class color
        */
        let classLabel = $('<label>Class: </label>');
        let classDropdown = $('<select style="width: 100%; margin-bottom: 5px;"></select>');
        
        // Add default option
        classDropdown.append('<option value="">Select Class...</option>');
        
        // Add all available classes to the dropdown
        const availableClasses = getAllClasses();
        Object.keys(availableClasses).forEach(className => {
          const color = availableClasses[className];
          classDropdown.append(`<option value="${className}">${className.charAt(0).toUpperCase() + className.slice(1)}</option>`);
        });
        
        // Set current selection if object already has a class
        if (annotatedObject.className) {
          classDropdown.val(annotatedObject.className);
        }
        
        classDropdown.on('change', function() {
          const selectedClassName = this.value;
          if (selectedClassName) {
            // Assign class information to the annotation
            annotatedObject.className = selectedClassName;
            
            // Update colors to match the class
            const classColor = getClassColor(selectedClassName);
            annotatedObject.color = classColor;
            color.val(classColor);
            
            // Update visual elements with new color
            if (annotatedObject.dom) {
              annotatedObject.dom.style.borderColor = classColor;
            }
            div.css('border-color', classColor);
          }
        });

        /*
          CREATE COMMENT TEXTAREA - THE ANNOTATION NOTES FIELD
          
          This creates a textarea where users can add detailed comments or notes about
          the annotation. Think of it like adding a sticky note to a photo with additional
          context or observations about the annotated object.
          
          The textarea can be vertically stretched to accommodate longer comments, and
          the comment text is automatically saved with the annotation data.
        */
        let comment = $('<textarea placeholder="Comments..." rows="3" style="width: 100%; resize: vertical;"></textarea>');
        if (annotatedObject.comment) {          // If the object already has a comment
          comment.val(annotatedObject.comment); // Pre-fill the textarea with the existing comment
        }
        comment.on('change keyup paste mouseup', function() {
          annotatedObject.comment = this.value; // Save any changes immediately
        });

        /*
          CREATE COLOR PICKER - THE ANNOTATION COLOR SELECTOR
          
          This creates a color input that allows users to choose a custom color for
          each annotation. Think of it like selecting a highlighter color for marking
          different objects - red for cars, blue for people, green for buildings, etc.
          
          The color affects both the bounding box appearance and the control panel styling.
        */
        let colorLabel = $('<label>Color: </label>');
        let color = $('<input type="color" value="#FF0000" style="width: 40px; height: 25px; border: none; cursor: pointer;" />');
        if (annotatedObject.color) {          // If the object already has a color
          color.val(annotatedObject.color);   // Pre-fill the color picker with existing color
        }
        color.on('change', function() {
          annotatedObject.color = this.value; // Save the selected color
          // Update the bounding box color immediately
          if (annotatedObject.dom) {
            annotatedObject.dom.style.borderColor = this.value;
          }
          // Update the control panel border color to match
          div.css('border-color', this.value);
        });

        /*
          CREATE VISIBILITY CHECKBOX - THE SHOW/HIDE TOGGLE
          
          This creates a checkbox that controls whether this annotation is visible
          in the current frame. Think of it like a light switch for each annotation.
          
          When checked: The bounding box appears on screen
          When unchecked: The bounding box is hidden
          
          This is useful for:
          - Hiding annotations when objects go off-screen
          - Temporarily hiding annotations to see the video more clearly
          - Marking frames where an object is not visible due to occlusion
        */
        let visibleLabel = $('<label>');                                // Container for checkbox and label
        let visible = $('<input type="checkbox" checked="checked" />'); // Checkbox (starts checked)
        annotatedObject.visible = visible;                              // Store reference for other code to use
        
        visible.change(function() {
          let bbox; // Variable to hold bounding box data
          
          if (this.checked) {
            /*
              CHECKBOX WAS CHECKED - MAKE ANNOTATION VISIBLE
              
              Show the bounding box on screen and record its current position/size
              as an annotation for this frame. This tells the system "the object
              is visible at this location in this frame."
            */
            annotatedObject.dom.style.display = 'block'; // Show the bounding box
            let jquery = $(annotatedObject.dom);          // Convert to jQuery for easier measurement
            let position = jquery.position();             // Get current position
            
            // Create bounding box data with current position and size (rounded to whole pixels)
            bbox = new BoundingBox(Math.round(position.left), Math.round(position.top), Math.round(jquery.width()), Math.round(jquery.height()));
          } else {
            /*
              CHECKBOX WAS UNCHECKED - HIDE ANNOTATION
              
              Hide the bounding box and record that the object is not visible
              in this frame. This tells the system "the object is not visible
              in this frame" (maybe it went off-screen or behind something).
            */
            annotatedObject.dom.style.display = 'none'; // Hide the bounding box
            bbox = null; // No bounding box data (object not visible)
          }
          
          // Record the visibility state for this frame (marked as ground truth because human-set)
          annotatedObject.add(new AnnotatedFrame(player.currentFrame, bbox, true));
        });
        visibleLabel.append(visible);           // Add checkbox to label
        visibleLabel.append('Is visible?');     // Add descriptive text

        /*
          CREATE "HIDE OTHERS" CHECKBOX - THE FOCUS MODE TOGGLE
          
          This creates a checkbox for "focus mode" - when enabled, all other annotations
          are hidden so the user can focus on just this one object. Think of it like
          using a spotlight in a dark room to highlight one specific thing.
          
          This is useful for:
          - Focusing on one object when the screen is cluttered with many annotations
          - Taking screenshots or recordings that highlight a specific object
          - Reducing visual distraction during detailed annotation work
        */
        let hideLabel = $('<label>');                    // Container for checkbox and label
        let hide = $('<input type="checkbox" />');       // Checkbox (starts unchecked)
        hide.change(function() {
          annotatedObject.hideOthers = this.checked;    // Save the focus mode setting
        });
        hideLabel.append(hide);                          // Add checkbox to label
        hideLabel.append('Hide others?');                // Add descriptive text

        /*
          CREATE DELETE BUTTON - THE ANNOTATION REMOVER
          
          This creates a button that completely removes this annotation from the system.
          Think of it like a "shred" button that permanently destroys a document.
          
          When clicked:
          1. Find this annotation in the master list
          2. Remove all its visual elements from the screen
          3. Remove all its data from memory
          4. Remove its control panel
          
          This is a permanent action that can't be undone (no "undo" feature implemented).
        */
        let del = $('<input type="button" value="Delete" />');
        del.click(function() {
          // Search through all annotations to find this specific one
          for (let i = 0; i < annotatedObjectsTracker.annotatedObjects.length; i++) {
            if (annotatedObject === annotatedObjectsTracker.annotatedObjects[i]) {
              clearAnnotatedObject(i); // Remove this annotation completely
              break; // Stop searching once we found and removed it
            }
          }
        });

        /*
          ASSEMBLE THE CONTROL PANEL - PUTTING ALL PIECES TOGETHER
          
          Now we take all the individual controls we created and assemble them into
          a single control panel. Think of it like putting all the buttons and switches
          into a control box with a border around it.
          
          The layout is:
          - Name input field
          - ID input field
          - Comment textarea (vertically stretchable)
          - Visibility checkbox
          - Hide others checkbox
          - Delete button
          
          All separated by line breaks for readability.
        */
        let div = $('<div></div>'); // Create container for all controls
        let borderColor = annotatedObject.color || '#FF0000'; // Use object's color or default red
        div.css({
          'border': '2px solid ' + borderColor, // Border color matches annotation color
          'display': 'inline-block',       // Display as a box that sits next to other boxes
          'margin': '5px',                 // Space between this and other control panels
          'padding': '10px'                // Space between border and contents
        });
        
        // Add all the controls in order, with line breaks between them
        div.append(name);               // Name input field
        div.append($('<br />'));        // Line break
        div.append(id);                 // ID input field
        div.append($('<br />'));        // Line break
        div.append(comment);            // Comment textarea (vertically aligned with name and id)
        div.append($('<br />'));        // Line break
        div.append(colorLabel);         // Color label
        div.append(color);              // Color picker input
        div.append($('<br />'));        // Line break
        div.append(visibleLabel);       // Visibility checkbox with label
        div.append($('<br />'));        // Line break
        div.append(hideLabel);          // Hide others checkbox with label
        div.append($('<br />'));        // Line break
        div.append(del);                // Delete button

        annotatedObject.controls = div; // Store reference so we can remove it later

        $('#objects').append(div);      // Add the control panel to the objects area in the UI
      }

      /*
        GENERATE XML FUNCTION - THE ANNOTATION DATA EXPORTER
        
        This function converts all the annotation data into an XML file that can be
        saved and shared. Think of it like taking all the sticky notes you've placed
        on a photo and writing them down in a detailed report that someone else could
        use to recreate your annotations.
        
        XML (eXtensible Markup Language) is a structured text format that looks like
        HTML but is designed for storing data. It's like a very organized filing system
        where everything has labels and is nested in a logical hierarchy.
        
        The XML format used here is compatible with VATIC (Video Annotation Tool from Irvine, California),
        which is a research tool for video annotation. This allows our annotations to be
        used in academic research or other video analysis tools.
        
        What gets exported:
        1. Basic video information (filename, source, etc.)
        2. For each annotated object: name, ID, and movement data
        3. For each frame: exact position coordinates of the object
        4. Ground truth flags (whether human-annotated or computer-predicted)
        
        The process:
        1. Build XML structure as a text string
        2. Go through each annotated object
        3. For each object, go through every frame and record its position
        4. Save the final XML text as a downloadable file
      */
      function generateXml() {
        /*
          BUILD XML HEADER AND METADATA
          
          Start building the XML file with standard headers and metadata.
          This is like writing the title page and table of contents of a report.
        */
        let xml = '<?xml version="1.0" encoding="utf-8"?>\n';  // XML format declaration
        xml += '<annotation>\n';                                // Root element (like book cover)
        xml += '  <folder>not available</folder>\n';           // Source folder (not applicable here)
        xml += '  <filename>not available</filename>\n';       // Source filename (not applicable here)
        xml += '  <source>\n';                                 // Information about data source
        xml += '    <type>video</type>\n';                     // Source type is video
        xml += '    <sourceImage>vatic frames</sourceImage>\n'; // Frame extraction method
        xml += '    <sourceAnnotation>vatic</sourceAnnotation>\n'; // Annotation format
        xml += '  </source>\n';

        /*
          EXPORT CLASS DEFINITIONS
          
          Include all available annotation classes in the XML export for reference.
          This allows the XML to be self-contained with class information.
        */
        if (typeof getAllClasses === 'function') {
          const classes = getAllClasses();
          if (Object.keys(classes).length > 0) {
            xml += '  <classes>\n';
            Object.entries(classes).forEach(([className, color]) => {
              xml += `    <class name="${className}" color="${color}" />\n`;
            });
            xml += '  </classes>\n';
          }
        }

        /*
          PROCESS EACH ANNOTATED OBJECT
          
          Go through every object that has been annotated and export its complete
          tracking data. This is like writing a separate chapter for each character
          in a movie, describing where they appear in every scene.
        */
        let totalFrames = framesManager.frames.totalFrames(); // Get total frame count for validation
        
        for (let i = 0; i < annotatedObjectsTracker.annotatedObjects.length; i++) {
          let annotatedObject = annotatedObjectsTracker.annotatedObjects[i];

          /*
            WRITE OBJECT METADATA
            
            For each object, first write its basic information like name and ID.
            This is like writing the character's name and basic info at the start
            of their chapter.
          */
          xml += '  <object>\n';
          xml += '    <name>' + annotatedObject.name + '</name>\n';      // Object name (car, person, etc.)
          xml += '    <moving>true</moving>\n';                          // Assume all objects can move
          xml += '    <action/>\n';                                     // No specific action recorded
          xml += '    <verified>0</verified>\n';                        // Not verified by second annotator
          xml += '    <id>' + annotatedObject.id + '</id>\n';          // Unique object identifier
          // Include comment if it exists and is not empty
          if (annotatedObject.comment && annotatedObject.comment.trim() !== '') {
            xml += '    <comment>' + annotatedObject.comment.replace(/&/g, '&amp;').replace(/</g, '&lt;').replace(/>/g, '&gt;') + '</comment>\n';
          }
          // Include color if it exists
          if (annotatedObject.color) {
            xml += '    <color>' + annotatedObject.color + '</color>\n';
          }
          // Include class if it exists
          if (annotatedObject.className) {
            xml += '    <class>' + annotatedObject.className + '</class>\n';
          }
          xml += '    <createdFrame>0</createdFrame>\n';                // Frame where object first appears
          xml += '    <startFrame>0</startFrame>\n';                    // Frame where tracking starts
          xml += '    <endFrame>' + (totalFrames - 1 ) + '</endFrame>\n'; // Frame where tracking ends

          /*
            WRITE FRAME-BY-FRAME POSITION DATA
            
            For each frame in the video, record where this object is positioned.
            This is like writing down the exact coordinates of where a character
            stands in every single scene of a movie.
            
            Each position is recorded as a "polygon" (even though it's really a rectangle)
            with four corner points. This format is compatible with research tools that
            might handle more complex shapes.
          */
          for (let frameNumber = 0; frameNumber < totalFrames; frameNumber++) {
            let annotatedFrame = annotatedObject.get(frameNumber); // Get object position in this frame
            
            /*
              SAFETY CHECK - ENSURE COMPLETE DATA
              
              Before exporting, make sure we have position data for every frame.
              If any frame is missing data, it means the user needs to play through
              the entire video first to generate complete tracking information.
            */
            if (annotatedFrame == null) {
              window.alert('Play the video in full before downloading the XML so that bounding box data is available for all frames.');
              return; // Exit early if data is incomplete
            }

            let bbox = annotatedFrame.bbox; // Get the bounding box for this frame
            
            if (bbox != null) {
              /*
                OBJECT IS VISIBLE - RECORD ITS POSITION
                
                When the object is visible in this frame, record its position as
                a four-point polygon. We convert the bounding box (x, y, width, height)
                into four corner coordinates.
                
                The format is: top-left, bottom-left, bottom-right, top-right
                This creates a clockwise path around the object's boundary.
              */
              let isGroundThrugh = annotatedFrame.isGroundTruth ? 1 : 0; // Convert boolean to number

              xml += '    '; // Indentation for readability
              xml += '<polygon>';                                           // Start polygon element
              xml += '<t>' + frameNumber + '</t>';                          // Frame number (time)
              xml += '<pt><x>' + bbox.x + '</x><y>' + bbox.y + '</y><l>' + isGroundThrugh + '</l></pt>'; // Top-left corner
              xml += '<pt><x>' + bbox.x + '</x><y>' + (bbox.y + bbox.height) + '</y><l>' + isGroundThrugh + '</l></pt>'; // Bottom-left corner
              xml += '<pt><x>' + (bbox.x + bbox.width) + '</x><y>' + (bbox.y + bbox.height) + '</y><l>' + isGroundThrugh + '</l></pt>'; // Bottom-right corner
              xml += '<pt><x>' + (bbox.x + bbox.width) + '</x><y>' + bbox.y + '</y><l>' + isGroundThrugh + '</l></pt>'; // Top-right corner
              xml += '</polygon>\n';                                        // End polygon element
            }
            // Note: If bbox is null (object not visible), we don't write anything for this frame
          }

          xml += '  </object>\n'; // End this object's data section
        }

        xml += '</annotation>\n'; // End the entire XML document

        /*
          SAVE XML FILE TO USER'S COMPUTER
          
          Take the XML text we built and save it as a downloadable file.
          This uses the streamSaver library to handle the file download without
          needing to load the entire file into memory (important for large videos).
          
          The process:
          1. Create a write stream for a file named "output.xml"
          2. Convert the XML text to bytes (using TextEncoder)
          3. Write the bytes to the stream
          4. Close the stream (triggers the download)
        */
        let writeStream = streamSaver.createWriteStream('output.xml').getWriter(); // Create download stream
        let encoder = new TextEncoder();                                           // Create text-to-bytes converter
        writeStream.write(encoder.encode(xml));                                   // Convert XML to bytes and write
        writeStream.close();                                                      // Close stream (starts download)
      }

      /*
        IMPORT XML FUNCTION - THE ANNOTATION DATA IMPORTER
        
        This function does the opposite of generateXml() - it reads an XML file containing
        annotation data and recreates all the annotations in our system. Think of it like
        taking someone else's detailed report about where objects are in a video and using
        it to automatically place all the sticky notes in the right positions.
        
        This is useful for:
        1. Loading previously saved annotation work to continue editing
        2. Sharing annotation data between different users or systems
        3. Importing annotations created by other tools (if they use VATIC format)
        4. Collaborating on annotation projects
        
        The process:
        1. Read the XML file content
        2. Parse the XML structure to extract object and position data
        3. Recreate annotation objects with their control panels
        4. Restore all the frame-by-frame position data
        5. Display everything in the interface
        
        This function is called when the user selects an XML file in the import input.
      */
      function importXml() {
        /*
          SAFETY CHECK - ENSURE ONE FILE SELECTED
          
          Make sure the user actually selected exactly one XML file. Don't proceed
          if no file or multiple files were selected.
        */
        if (this.files.length != 1) {
          return; // Exit early if file selection is invalid
        }

        /*
          SET UP FILE READER - THE XML CONTENT EXTRACTOR
          
          FileReader is a browser tool that can read the contents of files selected
          by the user. Think of it like a scanner that can read documents and convert
          them to digital text that our program can understand.
          
          We set up an "onload" callback that will be called when the file reading
          is complete. This is necessary because file reading is asynchronous (takes time).
        */
        var reader = new FileReader();
        reader.onload = (e) => {
          /*
            FILE READING STATUS CHECKS
            
            Before we can use the file content, we need to make sure the reading
            process completed successfully. FileReader goes through different states
            as it reads, and we only want to proceed when it's completely done (state 2).
          */
          if (e.target.readyState != 2) {  // 2 = DONE state
            return; // Exit if file reading isn't complete yet
          }

          if (e.target.error) {
            throw 'file reader error'; // Stop if there was an error reading the file
          }

          /*
            PARSE XML CONTENT - CONVERTING TEXT TO DATA STRUCTURE
            
            The file content is just a long text string containing XML markup.
            We need to parse it (analyze its structure) to extract the meaningful
            annotation data. Think of it like taking a written recipe and breaking
            it down into ingredients and steps.
            
            jQuery's parseXML function converts the XML text into a structured object
            that we can search through and extract data from.
          */
          let xml = $($.parseXML(e.target.result)); // Parse XML text into searchable structure
          
          /*
            IMPORT CLASS DEFINITIONS
            
            Check if the XML contains class definitions and import them.
            This ensures class information is available when creating annotations.
          */
          if (typeof importClassesFromXML === 'function') {
            importClassesFromXML($.parseXML(e.target.result));
          }
          
          let objects = xml.find('object');          // Find all <object> elements (annotated objects)
          
          /*
            RECREATE EACH ANNOTATED OBJECT
            
            Go through each object definition in the XML and recreate it in our system.
            This is like reading a guest list and setting up a name tag and seat for
            each person mentioned.
          */
          for (let i = 0; i < objects.length; i++) {
            let object = $(objects[i]);                    // Current object element from XML
            let name = object.find('n').text();           // Extract object name
            let id = object.find('id').text();             // Extract object ID
            let comment = object.find('comment').text();   // Extract object comment (if exists)
            let color = object.find('color').text();       // Extract object color (if exists)
            let className = object.find('class').text();   // Extract object class (if exists)

            /*
              CREATE NEW ANNOTATION OBJECT
              
              Build a new annotation object in our system using the data from the XML.
              This creates the internal data structure and visual bounding box.
            */
            let annotatedObject = new AnnotatedObject();  // Create new annotation object
            annotatedObject.name = name;                   // Set the name from XML
            annotatedObject.id = id;                       // Set the ID from XML
            if (comment) {                                 // Set the comment from XML if it exists
              annotatedObject.comment = comment;
            }
            if (color) {                                   // Set the color from XML if it exists
              annotatedObject.color = color;
            } else {
              annotatedObject.color = '#FF0000';       // Default to red if no color in XML
            }
            if (className) {                               // Set the class from XML if it exists
              annotatedObject.className = className;
              // Import the class if it doesn't exist in our class manager
              if (!annotationClasses.hasOwnProperty(className)) {
                annotationClasses[className] = color || '#FF0000';
                updateClassDisplay();
                updateClassDropdown();
              }
            }
            annotatedObject.dom = newBboxElement();        // Create visual bounding box element
            if (annotatedObject.color) {                   // Apply the color to the visual element
              annotatedObject.dom.style.borderColor = annotatedObject.color;
            }
            annotatedObjectsTracker.annotatedObjects.push(annotatedObject); // Add to tracking system
            
            // Create annotation card in the individual annotations UI for XML-loaded annotation
            if (window.annotationManager) {
              const classInfo = className ? {
                name: className,
                color: annotatedObject.color
              } : null;
              
              window.annotationManager.createAnnotationCard(annotatedObject, classInfo);
            }

            /*
              MAKE THE ANNOTATION INTERACTIVE
              
              Enable resize and drag functionality for this annotation, just like
              annotations created by hand. The onChange callback updates the annotation
              when the user modifies it after import.
            */
            interactify(
              annotatedObject.dom,
              (x, y, width, height) => {
                let bbox = new BoundingBox(x, y, width, height);
                annotatedObject.add(new AnnotatedFrame(player.currentFrame, bbox, true));
              }
            );

            // Create the control panel for this annotation (name input, checkboxes, etc.)
            addAnnotatedObjectControls(annotatedObject);

            /*
              RESTORE FRAME-BY-FRAME POSITION DATA
              
              Go through all the polygon elements in the XML and recreate the complete
              tracking history for this object. Each polygon represents where the object
              was positioned in a specific frame.
              
              This is like reading through a detailed log of where someone was at each
              moment in time and recreating their complete path of movement.
            */

            /*
              RESTORE FRAME-BY-FRAME POSITION DATA
              
              Go through all the polygon elements in the XML and recreate the complete
              tracking history for this object. Each polygon represents where the object
              was positioned in a specific frame.
              
              This is like reading through a detailed log of where someone was at each
              moment in time and recreating their complete path of movement.
            */
            let lastFrame = -1; // Track the last frame we processed (for gap detection)
            let polygons = object.find('polygon'); // Find all position records for this object
            
            for (let j = 0; j < polygons.length; j++) {
              let polygon = $(polygons[j]);                         // Current position record
              let frameNumber = parseInt(polygon.find('t').text()); // Which frame this position is for
              let pts = polygon.find('pt');                         // Get all four corner points
              let topLeft = $(pts[0]);                              // First point (top-left corner)
              let bottomRight = $(pts[2]);                          // Third point (bottom-right corner)
              let isGroundThrough = parseInt(topLeft.find('l').text()) == 1; // Whether human-annotated

              /*
                EXTRACT POSITION COORDINATES
                
                Convert the four-point polygon back into a simple bounding box.
                We only need the top-left and bottom-right corners to recreate
                the full rectangle. Think of it like knowing two opposite corners
                of a picture frame - that's enough to recreate the whole frame.
              */
              let x = parseInt(topLeft.find('x').text());      // Left edge position
              let y = parseInt(topLeft.find('y').text());      // Top edge position
              let w = parseInt(bottomRight.find('x').text()) - x; // Width (right edge - left edge)
              let h = parseInt(bottomRight.find('y').text()) - y; // Height (bottom edge - top edge)

              /*
                HANDLE FRAME GAPS - INVISIBLE PERIODS
                
                If there's a gap between the last frame we processed and this frame,
                it means the object was not visible during that period. We need to
                record this gap so the system knows the object was hidden.
                
                For example, if we processed frame 5 and now we're at frame 10,
                we need to record that the object was invisible from frame 6 to 9.
              */
              if (lastFrame + 1 != frameNumber) {
                // Create an "invisible" annotation frame for the gap period
                let annotatedFrame = new AnnotatedFrame(lastFrame + 1, null, true);
                annotatedObject.add(annotatedFrame);
              }

              /*
                CREATE POSITION RECORD FOR THIS FRAME
                
                Create the bounding box and annotation frame for this specific position.
                This records exactly where the object was positioned in this frame.
              */
              let bbox = new BoundingBox(x, y, w, h); // Create bounding box with extracted coordinates
              let annotatedFrame = new AnnotatedFrame(frameNumber, bbox, isGroundThrough); // Create frame annotation
              annotatedObject.add(annotatedFrame); // Add to object's tracking history

              lastFrame = frameNumber; // Update our position for gap detection
            }

            /*
              HANDLE FINAL GAP - POST-TRACKING INVISIBILITY
              
              If the last position record doesn't go all the way to the end of the video,
              we need to record that the object becomes invisible for the remaining frames.
              
              For example, if the video has 100 frames but the last position record is
              for frame 80, we need to mark the object as invisible for frames 81-100.
            */
            if (lastFrame + 1 < framesManager.frames.totalFrames()) {
              let annotatedFrame = new AnnotatedFrame(lastFrame + 1, null, true);
              annotatedObject.add(annotatedFrame);
            }
          }

          /*
            REFRESH DISPLAY WITH IMPORTED DATA
            
            After importing all the annotation data, update the display to show the
            annotations for the current frame. This makes the imported annotations
            immediately visible to the user.
          */
          player.drawFrame(player.currentFrame);
        };
        
        /*
          START THE FILE READING PROCESS
          
          Tell the FileReader to start reading the selected XML file as text.
          When it's done, the onload callback we set up above will be called.
        */
        reader.readAsText(this.files[0]); // Read the selected file as text
      }

      /*
        KEYBOARD SHORTCUTS SYSTEM - THE HOTKEY CONTROLLER
        
        This function sets up keyboard shortcuts that make the annotation tool much faster
        and easier to use. Think of it like learning keyboard shortcuts in any software
        (Ctrl+C for copy, Ctrl+V for paste) - once you know them, you can work much more
        efficiently without constantly reaching for the mouse.
        
        The system works by listening for key presses anywhere on the page and checking
        which key was pressed. Based on the key, it performs the appropriate action.
        
        Why keyboard shortcuts are important for annotation:
        1. Speed: Much faster than clicking buttons with the mouse
        2. Workflow: Keep hands in annotation position without interruption
        3. Precision: Some actions (like frame stepping) need quick, repeated use
        4. Professional feel: Makes the tool feel responsive and professional
        
        The function returns whether to "preventDefault" - this tells the browser
        whether to block the normal action of the key (like spacebar scrolling the page).
      */
      window.onkeydown = function(e) {
        let preventDefault = true; // Assume we'll handle the key and block browser default

        if (e.keyCode === 32) { // SPACEBAR - PLAY/PAUSE TOGGLE
          /*
            SPACEBAR - THE UNIVERSAL PLAY/PAUSE KEY
            
            This is the most common video player shortcut. Every video player
            (YouTube, Netflix, VLC, etc.) uses spacebar for play/pause.
            
            Why spacebar?
            1. Large key that's easy to hit without looking
            2. Central location accessible to either hand
            3. Universal convention across all video software
            4. Natural "stop/go" feeling
          */
          player.toogle(); // Note: "toogle" is a typo in original code, should be "toggle"
        } else if (e.keyCode === 78) { // N KEY - NEW ANNOTATION MODE
          /*
            N KEY - ENTER ANNOTATION CREATION MODE
            
            Pressing 'N' (for "New") switches the cursor to crosshair mode, indicating
            the user can now click and drag to create a new bounding box annotation.
            
            Why 'N' key?
            1. 'N' for "New annotation"
            2. Easy to remember mnemonic
            3. Left hand position (keeps right hand free for mouse)
            4. Not used by browser for other functions
            
            After pressing 'N', the user can:
            1. Click once to start drawing a box
            2. Drag to size the box  
            3. Click again to finish the box
          */
          doodle.style.cursor = 'crosshair'; // Change cursor to indicate annotation mode
        } else if (e.keyCode === 27) { // ESCAPE KEY - CANCEL CURRENT ACTION
          /*
            ESCAPE KEY - THE UNIVERSAL CANCEL KEY
            
            Escape is the standard "get me out of here" key in almost all software.
            It cancels whatever action is currently in progress and returns to normal state.
            
            In annotation mode, Escape:
            1. Cancels any box currently being drawn (removes it completely)
            2. Returns cursor to normal mode (exits annotation creation)
            3. Clears any temporary state
            
            This gives users a safe "oops, I didn't mean to do that" option.
          */
          if (tmpAnnotatedObject != null) {
            /*
              CLEAN UP INCOMPLETE ANNOTATION
              
              If the user was in the middle of drawing a bounding box, remove it
              completely and clean up. This is like erasing a pencil sketch that
              you decided you don't want.
            */
            doodle.removeChild(tmpAnnotatedObject.dom); // Remove the visual element
            tmpAnnotatedObject = null;                   // Clear the temporary object
          }

          doodle.style.cursor = 'default'; // Return to normal cursor
        } else if (e.keyCode == 37) { // LEFT ARROW - PREVIOUS FRAME
          /*
            LEFT ARROW - STEP BACKWARD ONE FRAME
            
            This allows frame-by-frame navigation backward through the video.
            Think of it like the "previous page" function when reading a book.
            
            Why left arrow?
            1. Intuitive direction (left = backward in time)
            2. Standard convention in video editing software
            3. Natural position for repeated use
            4. Matches right arrow for forward
            
            This is essential for precise annotation work where you need to see
            exactly how objects move between individual frames.
          */
          player.seek(player.currentFrame - 1); // Go to the previous frame
        } else if (e.keyCode == 39) { // RIGHT ARROW - NEXT FRAME
          /*
            RIGHT ARROW - STEP FORWARD ONE FRAME
            
            This allows frame-by-frame navigation forward through the video.
            Think of it like the "next page" function when reading a book.
            
            Why right arrow?
            1. Intuitive direction (right = forward in time)
            2. Standard convention in video editing software
            3. Natural position for repeated use
            4. Matches left arrow for backward
            
            Combined with left arrow, this gives precise frame-level control
            for detailed annotation work.
          */
          player.seek(player.currentFrame + 1); // Go to the next frame
        } else {
          /*
            UNHANDLED KEY - LET BROWSER HANDLE IT
            
            If the pressed key isn't one of our shortcuts, we don't want to
            interfere with it. Set preventDefault to false so the browser
            can handle the key normally (typing in text fields, etc.).
          */
          preventDefault = false;
        }

        /*
          PREVENT DEFAULT BROWSER ACTION (IF NEEDED)
          
          If we handled the key press, prevent the browser from doing its
          normal action. For example, spacebar normally scrolls the page,
          but we want it to play/pause the video instead.
          
          This is like telling the browser "I've got this key handled,
          don't do your usual thing with it."
        */
        if (preventDefault) {
          e.preventDefault();
        }
      };

      /*
        EXPORT ANNOTATED VIDEO FUNCTION - THE VIDEO CREATOR WITH BURNED-IN ANNOTATIONS
        
        This function creates a new video file that has all the annotation bounding boxes
        permanently drawn on top of the original video frames. Think of it like taking
        a video and permanently drawing boxes and labels on it, then saving it as a new video.
        
        "Burned-in" means the annotations become part of the video pixels themselves,
        not separate overlay data. It's like the difference between:
        - A movie with optional subtitles (can be turned on/off)
        - A movie with subtitles permanently painted onto each frame
        
        This is useful for:
        1. Sharing annotated videos with people who don't have annotation software
        2. Creating demonstration videos that show what was detected/tracked
        3. Making training materials or presentations
        4. Archiving results where the annotations are part of the visual record
        
        The process:
        1. Create a virtual canvas for drawing each frame
        2. Set up video recording from the canvas
        3. For each frame: draw the original + annotations on canvas
        4. Let the video recorder capture each frame
        5. When done, save the recorded video file
      */
      function exportAnnotatedFramesAsVideo() {
        const totalFrames = framesManager.frames.totalFrames();
        
        /*
          SAFETY CHECK - ENSURE WE HAVE FRAMES TO EXPORT
          
          Don't proceed if there are no frames loaded. This prevents errors
          and gives the user a clear message about what's wrong.
        */
        if (totalFrames === 0) {
          alert('No frames available to export.');
          return;
        }

        /*
          SETUP PROGRESS DISPLAY AND DISABLE CONTROLS
          
          Show a progress bar and disable export buttons during processing.
          This prevents users from starting multiple exports simultaneously
          and gives visual feedback about the operation's progress.
        */
        exportProgressDiv.style.display = 'block';      // Show progress area
        exportVideoButton.disabled = true;              // Disable video export button
        exportAnnotatedZipButton.disabled = true;       // Disable ZIP export button
        exportProgressBar.value = 0;                    // Reset progress bar to 0%
        exportProgressText.textContent = '0%';          // Reset progress text

        /*
          SETUP CANVAS DIMENSIONS USING FIRST FRAME
          
          We need to know the video dimensions to create the output video.
          Get the first frame to determine the width and height that all
          frames should have.
        */
        annotatedObjectsTracker.getFrameWithObjects(0).then((firstFrameWithObjects) => {
          /*
            CREATE VIRTUAL CANVAS FOR VIDEO GENERATION
            
            This canvas exists only in memory (not visible on the page).
            Think of it like a digital easel where we'll paint each frame
            before the video recorder captures it.
            
            We set it to the same dimensions as the video frames so the
            output video will be the correct size.
          */
          const canvas = document.createElement('canvas');  // Create invisible canvas
          const ctx = canvas.getContext('2d');             // Get drawing context
          
          canvas.width = firstFrameWithObjects.img.width;   // Set canvas width to match video
          canvas.height = firstFrameWithObjects.img.height; // Set canvas height to match video

          /*
            SETUP VIDEO RECORDING FROM CANVAS
            
            Modern browsers can record video from a canvas element. We set up:
            1. A stream that captures the canvas content
            2. A MediaRecorder that converts the stream to video format
            3. Storage for the video data chunks as they're generated
            
            Think of it like pointing a camera at our digital easel and
            hitting record while we paint each frame.
          */
          const stream = canvas.captureStream();                            // Create video stream from canvas
          const recorder = new MediaRecorder(stream, { mimeType: 'video/webm' }); // Create video recorder
          const chunks = [];                                                 // Array to store video data

          /*
            SETUP RECORDING EVENT HANDLERS
            
            Define what happens when the recorder generates data and when it finishes.
          */
          recorder.ondataavailable = (event) => {
            chunks.push(event.data); // Collect video data chunks as they're generated
          };

          recorder.onstop = () => {
            /*
              FINALIZE AND DOWNLOAD THE VIDEO
              
              When recording stops, combine all the data chunks into a complete
              video file and trigger a download to the user's computer.
            */
            const blob = new Blob(chunks, { type: 'video/webm' }); // Combine chunks into video file
            const url = URL.createObjectURL(blob);                 // Create download URL

            /*
              TRIGGER AUTOMATIC DOWNLOAD
              
              Create a temporary download link and automatically click it.
              This is the standard way to trigger file downloads from JavaScript.
            */
            const a = document.createElement('a'); // Create download link
            a.style.display = 'none';              // Make it invisible
            a.href = url;                         // Set download URL
            a.download = 'annotated-frames.webm';  // Set filename
            document.body.appendChild(a);          // Add to page (required for click)
            a.click();                             // Trigger download
            document.body.removeChild(a);          // Remove from page
            URL.revokeObjectURL(url);              // Clean up memory
            
            /*
              CLEANUP INTERFACE
              
              Hide the progress display and re-enable the export buttons
              so the user can export again if needed.
            */
            exportProgressDiv.style.display = 'none'; // Hide progress area
            exportVideoButton.disabled = false;       // Re-enable video export button
            exportAnnotatedZipButton.disabled = false; // Re-enable ZIP export button
          };

          recorder.start(); // Begin video recording

          /*
            FRAME PROCESSING FUNCTION - THE MAIN EXPORT LOOP
            
            This function processes each frame individually, drawing the original
            frame plus annotations onto the canvas, then moving to the next frame.
            
            It's designed as a recursive function that calls itself for the next
            frame after finishing the current one. This ensures frames are processed
            in order and gives the video recorder time to capture each frame.
          */
          const processFrame = (frameIndex) => {
            /*
              CHECK FOR COMPLETION
              
              If we've processed all frames, stop the video recorder.
              This will trigger the onstop event handler above.
            */
            if (frameIndex >= totalFrames) {
              recorder.stop(); // Stop recording (triggers download)
              return;
            }

            /*
              UPDATE PROGRESS DISPLAY
              
              Show the user how much of the export is complete.
              Calculate percentage and update both the progress bar and text.
            */
            const progress = Math.round((frameIndex / totalFrames) * 100);
            exportProgressBar.value = progress;
            exportProgressText.textContent = `${progress}% (${frameIndex}/${totalFrames})`;

            /*
              DRAW CURRENT FRAME WITH ANNOTATIONS
              
              Get the frame data with all its annotations and draw everything
              onto the canvas. This is the same drawing logic used for display,
              but now we're drawing to a canvas that gets recorded as video.
            */
            annotatedObjectsTracker.getFrameWithObjects(frameIndex).then((frameWithObjects) => {
              /*
                DRAW THE BASE FRAME
                
                First, draw the original video frame onto the canvas.
                This provides the background image.
              */
              ctx.drawImage(frameWithObjects.img, 0, 0);
              
              /*
                DRAW EACH ANNOTATION
                
                Go through all the annotated objects and draw their bounding
                boxes and labels if they're visible in this frame.
              */
              for (let i = 0; i < frameWithObjects.objects.length; i++) {
                let object = frameWithObjects.objects[i];
                let annotatedObject = object.annotatedObject;
                let annotatedFrame = object.annotatedFrame;
                
                if (annotatedFrame.isVisible() && annotatedFrame.bbox) {
                  let bbox = annotatedFrame.bbox;
                  
                  /*
                    SET ANNOTATION-SPECIFIC COLOR
                    
                    Use the annotation's custom color if available, otherwise default to red.
                  */
                  let annotationColor = annotatedObject.color || '#FF0000';
                  ctx.strokeStyle = annotationColor; // Use annotation's color for bounding box
                  ctx.lineWidth = 2;                 // 2-pixel thick lines
                  ctx.font = '16px Arial';           // Font for object labels
                  ctx.fillStyle = annotationColor;   // Use annotation's color for text
                  
                  /*
                    DRAW BOUNDING BOX RECTANGLE
                    
                    Draw the rectangular outline around the object.
                  */
                  ctx.strokeRect(bbox.x, bbox.y, bbox.width, bbox.height);
                  
                  /*
                    DRAW OBJECT LABEL
                    
                    If the object has a meaningful name (not the default "Name?"),
                    draw it above the bounding box for identification.
                  */
                  if (annotatedObject.name && annotatedObject.name !== 'Name?') {
                    ctx.fillText(annotatedObject.name, bbox.x, bbox.y - 5);
                  }
                }
              }
              
              /*
                PROCEED TO NEXT FRAME
                
                Wait a brief moment (100ms) then process the next frame.
                The delay ensures the video recorder has time to capture this frame
                before we overwrite the canvas with the next frame.
              */
              setTimeout(() => processFrame(frameIndex + 1), 100);
              
            }).catch((error) => {
              /*
                ERROR HANDLING
                
                If there's an error processing this frame, log it and skip to
                the next frame. This prevents one bad frame from stopping the
                entire export process.
              */
              console.error(`Error processing frame ${frameIndex}:`, error);
              setTimeout(() => processFrame(frameIndex + 1), 100); // Skip and continue
            });
          };

          processFrame(0); // Start processing from frame 0
          
        }).catch(() => {
          /*
            FIRST FRAME ERROR HANDLING
            
            If we can't get the first frame (to determine dimensions),
            show an error and clean up the interface.
          */
          alert('Failed to fetch the first frame.');
          exportProgressDiv.style.display = 'none';
          exportVideoButton.disabled = false;
          exportAnnotatedZipButton.disabled = false;
        });
      }

      /*
        EXPORT ANNOTATED FRAMES AS ZIP FUNCTION - THE FRAME COLLECTION EXPORTER
        
        This function creates a ZIP file containing individual image files, where each
        image is one frame from the video with annotations drawn on it. Think of it like
        taking every page of a flip-book, drawing annotations on each page, then putting
        all the pages in a folder to share.
        
        Unlike the video export (which creates one video file), this creates many individual
        image files. This is useful for:
        1. Frame-by-frame analysis where you need to examine individual frames
        2. Creating training datasets for machine learning (each frame is a separate example)
        3. Integration with other tools that work with image sequences
        4. Manual review where you want to scroll through images at your own pace
        5. Creating presentations where you need specific frames as slides
        
        The process:
        1. Create a ZIP file container
        2. For each frame: draw original + annotations on a canvas
        3. Convert the canvas to an image file
        4. Add the image to the ZIP with a sequential filename
        5. When all frames are processed, download the complete ZIP
      */
      function exportAnnotatedFramesAsZip() {
        const totalFrames = framesManager.frames.totalFrames();
        
        /*
          SAFETY CHECK - ENSURE WE HAVE FRAMES TO EXPORT
        */
        if (totalFrames === 0) {
          alert('No frames available to export.');
          return;
        }

        /*
          SETUP PROGRESS DISPLAY AND DISABLE CONTROLS
          
          Same as video export - show progress and prevent multiple simultaneous operations.
        */
        exportProgressDiv.style.display = 'block';      // Show progress area
        exportVideoButton.disabled = true;              // Disable video export button
        exportAnnotatedZipButton.disabled = true;       // Disable ZIP export button
        exportProgressBar.value = 0;                    // Reset progress bar
        exportProgressText.textContent = '0%';          // Reset progress text

        /*
          CREATE ZIP FILE CONTAINER
          
          JSZip is a library that creates ZIP files in the browser. Think of it
          like getting an empty folder that we'll fill with image files.
        */
        const zip = new JSZip();
        let processedFrames = 0; // Counter to track completion

        /*
          FRAME PROCESSING FUNCTION - THE MAIN EXPORT LOOP
          
          Similar to video export, but instead of recording video, we create
          individual image files and add them to a ZIP archive.
          
          This is designed as a recursive function to ensure frames are processed
          in order and to prevent overwhelming the browser with too many simultaneous
          operations.
        */
        const processFrame = (frameIndex) => {
          /*
            CHECK FOR COMPLETION
            
            If we've processed all frames, generate the final ZIP file and download it.
          */
          if (frameIndex >= totalFrames) {
            /*
              GENERATE AND DOWNLOAD ZIP FILE
              
              Convert all the image files we've collected into a single downloadable
              ZIP archive. This is done asynchronously since large ZIP files take
              time to generate.
            */
            exportProgressText.textContent = 'Generating zip file...'; // Update status message
            zip.generateAsync({type: 'blob'}).then((content) => {
              /*
                TRIGGER ZIP FILE DOWNLOAD
                
                Same download mechanism as video export, but for a ZIP file.
              */
              const url = URL.createObjectURL(content);         // Create download URL
              const a = document.createElement('a');            // Create download link
              a.style.display = 'none';                        // Make it invisible
              a.href = url;                                     // Set download URL
              a.download = 'annotated-frames.zip';             // Set filename
              document.body.appendChild(a);                    // Add to page
              a.click();                                        // Trigger download
              document.body.removeChild(a);                    // Remove from page
              URL.revokeObjectURL(url);                        // Clean up memory
              
              /*
                CLEANUP INTERFACE
                
                Hide progress and re-enable buttons for potential future exports.
              */
              exportProgressDiv.style.display = 'none';        // Hide progress area
              exportVideoButton.disabled = false;              // Re-enable video export button
              exportAnnotatedZipButton.disabled = false;       // Re-enable ZIP export button
            });
            return; // Exit the recursive function
          }

          /*
            UPDATE PROGRESS DISPLAY
            
            Show export progress to the user.
          */
          const progress = Math.round((frameIndex / totalFrames) * 100);
          exportProgressBar.value = progress;
          exportProgressText.textContent = `${progress}% (${frameIndex}/${totalFrames})`;

          /*
            PROCESS CURRENT FRAME
            
            Get the frame with annotations and draw everything onto a canvas,
            then convert to an image file for the ZIP.
          */
          annotatedObjectsTracker.getFrameWithObjects(frameIndex).then((frameWithObjects) => {
            /*
              CREATE TEMPORARY CANVAS FOR THIS FRAME
              
              Each frame gets its own canvas for drawing. This canvas exists only
              long enough to create one image file.
            */
            const canvas = document.createElement('canvas'); // Create temporary canvas
            const ctx = canvas.getContext('2d');            // Get drawing context
            
            // Set canvas size to match frame
            canvas.width = frameWithObjects.img.width;
            canvas.height = frameWithObjects.img.height;
            
            /*
              DRAW FRAME WITH ANNOTATIONS
              
              Same drawing process as video export - base frame plus annotations.
            */
            ctx.drawImage(frameWithObjects.img, 0, 0); // Draw base frame
            
            // Draw each annotation
            for (let i = 0; i < frameWithObjects.objects.length; i++) {
              let object = frameWithObjects.objects[i];
              let annotatedObject = object.annotatedObject;
              let annotatedFrame = object.annotatedFrame;
              
              if (annotatedFrame.isVisible() && annotatedFrame.bbox) {
                let bbox = annotatedFrame.bbox;
                
                // Set annotation-specific color
                let annotationColor = annotatedObject.color || '#FF0000';
                ctx.strokeStyle = annotationColor; // Use annotation's color for bounding box
                ctx.lineWidth = 2;                 // 2-pixel thick lines
                ctx.font = '16px Arial';           // Font for labels
                ctx.fillStyle = annotationColor;   // Use annotation's color for text
                
                // Draw bounding box rectangle
                ctx.strokeRect(bbox.x, bbox.y, bbox.width, bbox.height);
                
                // Draw object label if meaningful
                if (annotatedObject.name && annotatedObject.name !== 'Name?') {
                  ctx.fillText(annotatedObject.name, bbox.x, bbox.y - 5);
                }
              }
            }
            
            /*
              CONVERT CANVAS TO IMAGE FILE AND ADD TO ZIP
              
              The canvas.toBlob() method converts the drawn canvas into an image file
              (JPEG format with 90% quality). When the conversion is complete, we add
              the image to our ZIP archive with a sequential filename.
              
              Filename format: frame_000001.jpg, frame_000002.jpg, etc.
              The zero-padding ensures files sort correctly in file browsers.
            */
            canvas.toBlob((blob) => {
              // Create zero-padded filename (frame_000001.jpg, frame_000002.jpg, etc.)
              const frameFileName = `frame_${frameIndex.toString().padStart(6, '0')}.jpg`;
              zip.file(frameFileName, blob);  // Add image to ZIP archive
              processedFrames++;              // Increment completion counter
              
              /*
                PROCEED TO NEXT FRAME
                
                Shorter delay (10ms) than video export since we're not recording,
                just creating files. This makes ZIP export faster than video export.
              */
              setTimeout(() => processFrame(frameIndex + 1), 10);
            }, 'image/jpeg', 0.9); // JPEG format with 90% quality
            
          }).catch((error) => {
            /*
              ERROR HANDLING
              
              If there's an error processing this frame, log it and continue.
              Don't let one bad frame stop the entire export.
            */
            console.error(`Error processing frame ${frameIndex}:`, error);
            setTimeout(() => processFrame(frameIndex + 1), 10); // Skip and continue
          });
        };

        processFrame(0); // Start processing from frame 0
      }

      // Make key functions and variables globally accessible for annotation manager
      window.annotatedObjectsTracker = annotatedObjectsTracker;
      window.clearAnnotatedObject = clearAnnotatedObject;
      window.clearAllAnnotatedObjects = clearAllAnnotatedObjects;
      window.addAnnotatedObjectControls = addAnnotatedObjectControls;
      window.player = player;
     </script>

  </body>
</html>
